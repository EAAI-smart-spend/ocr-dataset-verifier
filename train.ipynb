{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011f64e8",
   "metadata": {},
   "source": [
    "# EasyOCR è¨“ç·´èˆ‡æ”¹å–„æŒ‡å—\n",
    "\n",
    "## ğŸ¯ ç›®æ¨™\n",
    "æ”¹å–„ EasyOCR å°å°ç£ç™¼ç¥¨/æ”¶æ“šçš„ç¹é«”ä¸­æ–‡è¾¨è­˜æº–ç¢ºåº¦\n",
    "\n",
    "## âš ï¸ é‡è¦æé†’\n",
    "**è¨“ç·´ EasyOCR æ˜¯ä¸€å€‹éå¸¸è¤‡é›œä¸”è€—æ™‚çš„éç¨‹,éœ€è¦:**\n",
    "- å¤§é‡æ¨™è¨»æ•¸æ“š (æ•¸åƒåˆ°æ•¸è¬å¼µåœ–ç‰‡)\n",
    "- å¼·å¤§çš„ GPU è³‡æº (è‡³å°‘ RTX 3090 æˆ–æ›´å¥½)\n",
    "- æ·±åº¦å­¸ç¿’å°ˆæ¥­çŸ¥è­˜\n",
    "- æ•¸å¤©åˆ°æ•¸é€±çš„è¨“ç·´æ™‚é–“\n",
    "\n",
    "## ğŸ“‹ æœ¬æŒ‡å—åŒ…å«:\n",
    "\n",
    "### æ–¹æ¡ˆ A: ä¸è¨“ç·´çš„æ”¹å–„æ–¹æ³• (æ¨è–¦)\n",
    "1. åƒæ•¸èª¿å„ª\n",
    "2. åœ–ç‰‡é è™•ç†\n",
    "3. å¾Œè™•ç†èˆ‡ä¿®æ­£\n",
    "4. ä½¿ç”¨å¤šå€‹ OCR å¼•æ“\n",
    "\n",
    "### æ–¹æ¡ˆ B: ä½¿ç”¨é·ç§»å­¸ç¿’ (ä¸­ç­‰é›£åº¦)\n",
    "5. Fine-tune ç¾æœ‰æ¨¡å‹\n",
    "\n",
    "### æ–¹æ¡ˆ C: å®Œæ•´è¨“ç·´ (æœ€è¤‡é›œ)\n",
    "6. å¾é ­è¨“ç·´ EasyOCR\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24d94c",
   "metadata": {},
   "source": [
    "## æ–¹æ¡ˆ A1: åƒæ•¸èª¿å„ª (æœ€ç°¡å–®,æœ€æœ‰æ•ˆ)\n",
    "\n",
    "**ä¸éœ€è¦è¨“ç·´,åªéœ€èª¿æ•´ EasyOCR çš„åƒæ•¸**\n",
    "\n",
    "é€™æ˜¯æœ€å¿«é€Ÿä¸”æœ‰æ•ˆçš„æ”¹å–„æ–¹æ³•!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b489c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æ¸¬è©¦ 1: é è¨­åƒæ•¸\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wing199901/GitHub/SHape/smart-spend-backend/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.64] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³å£¼72è™Ÿèˆ–\n",
      "[0.81] Te1;2495-0822\n",
      "[0.42] T1 Io\n",
      "[1.00] 5\n",
      "[1.00] Cardno\n",
      "[1.00] 800012\n",
      "[0.96] Staff\n",
      "[1.00] ç¶“ç†\n",
      "[0.65] Guest Ilo.\n",
      "[0.61] Date: 2025-09-26\n",
      "[0.49] Time;\n",
      "[0.50] 18;38\n",
      "[0.68] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[0.92] 98.0\n",
      "[0.93] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.71] 18.0\n",
      "[0.99] 17;50\n",
      "[0.84] CO5è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.81] æ»¿]è¾£)\n",
      "[0.83] 78.0\n",
      "[0.86] 17;50 D08æŸ´èœå·é£¯\n",
      "[0.82] 62.0\n",
      "[0.90] Sub Tota1\n",
      "[0.59] 315.0\n",
      "[0.98] (0000119183)\n",
      "[0.62] 10% Service:\n",
      "[0.66] 31,60\n",
      "[0.54] Tota1\n",
      "[0.80] $348.0\n",
      "[0.81] Tota1\n",
      "[0.99] $348.0\n",
      "[1.00] Cash\n",
      "[1.00] $348.0\n",
      "[0.97] Helcome\n",
      "\n",
      "============================================================\n",
      "æ¸¬è©¦ 2: èª¿æ•´æ–‡å­—æª¢æ¸¬é–¾å€¼\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wing199901/GitHub/SHape/smart-spend-backend/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.54] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è€‹72è™Ÿèˆ–\n",
      "[0.76] Te1;2495-0822\n",
      "[0.43] T1 Io.\n",
      "[1.00] 5\n",
      "[0.68] Cardno; 800012\n",
      "[0.96] Staff: ç¶“ç†\n",
      "[0.89] Guest Ilo.\n",
      "[0.99] 2\n",
      "[0.63] Date: 2025-09-25\n",
      "[0.57] Time: 18:38\n",
      "[0.88] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[1.00] 98.0\n",
      "[0.96] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.82] 78.0\n",
      "[0.94] 17;50 C05è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.85] æ»¿]è¾£)\n",
      "[0.50] 18.0\n",
      "[0.48] 17;50 D08æŸ´èœå·é£¯\n",
      "[0.75] 62.0\n",
      "[0.88] Sub Tota1\n",
      "[1.00] 316.0\n",
      "[0.96] (0000119183)\n",
      "[0.55] 10% Service:\n",
      "[0.58] 31,60\n",
      "[0.95] Total\n",
      "[0.99] $348.0\n",
      "[0.69] Tota1\n",
      "[0.99] $348.0\n",
      "[1.00] Cash\n",
      "[0.89] $348.0\n",
      "[0.97] Helcome\n",
      "\n",
      "============================================================\n",
      "æ¸¬è©¦ 3: èª¿æ•´åœ–ç‰‡å¤§å°åƒæ•¸\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wing199901/GitHub/SHape/smart-spend-backend/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.79] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è€‹72è™Ÿèˆ–\n",
      "[0.65] Te1;2495-0822\n",
      "[0.90] #;\n",
      "[1.00] 5\n",
      "[0.63] Cardno; 80oo12\n",
      "[0.95] Staff: ç¶“ç†\n",
      "[0.63] Guest Ilo.;\n",
      "[0.31] Date: 2025-09-25\n",
      "[0.95] Time;\n",
      "[0.50] 18;38\n",
      "[0.60] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[0.99] 98.0\n",
      "[0.92] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.90] 18.0\n",
      "[0.93] 17;50 C05è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.87] æ»¿]è¾£)\n",
      "[0.48] 78.0\n",
      "[0.51] 17;50 008æŸ´èœå·é£¯\n",
      "[0.56] 62,0\n",
      "[0.91] Sub Tota1\n",
      "[0.39] 316.0\n",
      "[0.99] (0000119183)\n",
      "[0.64] 10% Service:\n",
      "[0.42] 31 ,60\n",
      "[0.63] Tota1\n",
      "[0.96] $348.0\n",
      "[0.56] Total\n",
      "[0.64] $348.0\n",
      "[1.00] Cash\n",
      "[0.97] $348.0\n",
      "[0.56] HeIcome\n",
      "\n",
      "============================================================\n",
      "æ¸¬è©¦ 4: ç¶œåˆå„ªåŒ–åƒæ•¸\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wing199901/GitHub/SHape/smart-spend-backend/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.66] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³å£¼72è™Ÿèˆ–\n",
      "[0.87] Te1;2495-0822\n",
      "[1.00] 5\n",
      "[0.74] Cardno; 800o12\n",
      "[0.88] Staff: ç¶“ç†\n",
      "[0.46] Guest llo.: 2\n",
      "[0.46] Date: 2025-09-26\n",
      "[0.54] Time; 18:38\n",
      "[0.83] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[0.99] 98.0\n",
      "[0.98] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.61] 78.0\n",
      "[0.50] 17;50 C05è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.87] æ»¿]è¾£)\n",
      "[0.62] 18.0\n",
      "[0.47] 17;50 D08ç´«èœå·é£¯\n",
      "[0.83] 62.0\n",
      "[0.64] Sub Tota1\n",
      "[0.95] 316.0\n",
      "[0.95] (0000119183)\n",
      "[0.62] 10% Service:\n",
      "[0.64] 31 ,60\n",
      "[0.92] Total\n",
      "[0.98] $348.0\n",
      "[0.63] Total\n",
      "[0.98] $348.0\n",
      "[1.00] Cash\n",
      "[0.85] $348.0\n",
      "[0.99] Helcome\n",
      "\n",
      "============================================================\n",
      "åƒæ•¸èªªæ˜:\n",
      "============================================================\n",
      "\n",
      "1. text_threshold (0-1): æ–‡å­—æª¢æ¸¬ä¿¡å¿ƒåº¦é–¾å€¼\n",
      "   - é™ä½ â†’ æª¢æ¸¬æ›´å¤šæ–‡å­— (å¯èƒ½å¢åŠ èª¤åˆ¤)\n",
      "   - æé«˜ â†’ åªæª¢æ¸¬é«˜ä¿¡å¿ƒåº¦æ–‡å­—\n",
      "\n",
      "2. low_text (0-1): ä½ä¿¡å¿ƒåº¦æ–‡å­—å€åŸŸé–¾å€¼\n",
      "   - é™ä½ â†’ æª¢æ¸¬æ›´å¤šæ¨¡ç³Šæ–‡å­—\n",
      "\n",
      "3. link_threshold (0-1): æ–‡å­—é€£æ¥é–¾å€¼\n",
      "   - é™ä½ â†’ æ›´å®¹æ˜“é€£æ¥åˆ†é–‹çš„å­—ç¬¦\n",
      "\n",
      "4. canvas_size: å…§éƒ¨è™•ç†çš„åœ–ç‰‡å¤§å°\n",
      "   - å¢åŠ  â†’ ä¿ç•™æ›´å¤šç´°ç¯€ (ä½†é€Ÿåº¦è®Šæ…¢)\n",
      "\n",
      "5. mag_ratio: åœ–ç‰‡æ”¾å¤§æ¯”ä¾‹\n",
      "   - å¢åŠ  â†’ å°å­—æ›´æ¸…æ™°\n",
      "\n",
      "6. min_size: æœ€å°æ–‡å­—å¤§å° (åƒç´ )\n",
      "   - é™ä½ â†’ æª¢æ¸¬æ›´å°çš„æ–‡å­—\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æ–¹æ¡ˆ A1: èª¿æ•´ EasyOCR åƒæ•¸ä»¥æ”¹å–„è¾¨è­˜\n",
    "\n",
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# åˆå§‹åŒ– reader\n",
    "reader = easyocr.Reader(['ch_tra', 'en'], gpu=True)\n",
    "\n",
    "# æ¸¬è©¦ä¸åŒåƒæ•¸çµ„åˆ\n",
    "image_path = './samples/2.jpeg'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ¸¬è©¦ 1: é è¨­åƒæ•¸\")\n",
    "print(\"=\"*60)\n",
    "result1 = reader.readtext(image_path, detail=1)\n",
    "for bbox, text, conf in result1:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¸¬è©¦ 2: èª¿æ•´æ–‡å­—æª¢æ¸¬é–¾å€¼\")\n",
    "print(\"=\"*60)\n",
    "result2 = reader.readtext(\n",
    "    image_path,\n",
    "    detail=1,\n",
    "    text_threshold=0.6,      # é™ä½ (é è¨­ 0.7) - æ›´å®¹æ˜“åµæ¸¬æ–‡å­—\n",
    "    low_text=0.3,            # é™ä½ (é è¨­ 0.4) - æª¢æ¸¬æ›´å¤šæ–‡å­—å€åŸŸ\n",
    "    link_threshold=0.3,      # é™ä½ (é è¨­ 0.4) - æ›´å®¹æ˜“é€£æ¥æ–‡å­—\n",
    ")\n",
    "for bbox, text, conf in result2:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¸¬è©¦ 3: èª¿æ•´åœ–ç‰‡å¤§å°åƒæ•¸\")\n",
    "print(\"=\"*60)\n",
    "result3 = reader.readtext(\n",
    "    image_path,\n",
    "    detail=1,\n",
    "    canvas_size=2560,        # å¢åŠ  (é è¨­ 2560) - è™•ç†æ›´å¤§çš„åœ–ç‰‡\n",
    "    mag_ratio=1.5,           # å¢åŠ  (é è¨­ 1) - æ”¾å¤§æ–‡å­—\n",
    ")\n",
    "for bbox, text, conf in result3:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¸¬è©¦ 4: ç¶œåˆå„ªåŒ–åƒæ•¸\")\n",
    "print(\"=\"*60)\n",
    "result4 = reader.readtext(\n",
    "    image_path,\n",
    "    detail=1,\n",
    "    paragraph=False,         # ä¸åˆä½µæ®µè½\n",
    "    min_size=10,             # æœ€å°æ–‡å­—å¤§å°\n",
    "    text_threshold=0.6,      # æ–‡å­—æª¢æ¸¬é–¾å€¼\n",
    "    low_text=0.3,            # ä½æ–‡å­—é–¾å€¼\n",
    "    link_threshold=0.3,      # é€£æ¥é–¾å€¼\n",
    "    canvas_size=2560,        # ç•«å¸ƒå¤§å°\n",
    "    mag_ratio=1.5,           # æ”¾å¤§æ¯”ä¾‹\n",
    "    contrast_ths=0.1,        # å°æ¯”åº¦é–¾å€¼\n",
    "    adjust_contrast=0.5,     # å°æ¯”åº¦èª¿æ•´\n",
    "    width_ths=0.7,           # å¯¬åº¦é–¾å€¼\n",
    ")\n",
    "for bbox, text, conf in result4:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"åƒæ•¸èªªæ˜:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. text_threshold (0-1): æ–‡å­—æª¢æ¸¬ä¿¡å¿ƒåº¦é–¾å€¼\n",
    "   - é™ä½ â†’ æª¢æ¸¬æ›´å¤šæ–‡å­— (å¯èƒ½å¢åŠ èª¤åˆ¤)\n",
    "   - æé«˜ â†’ åªæª¢æ¸¬é«˜ä¿¡å¿ƒåº¦æ–‡å­—\n",
    "\n",
    "2. low_text (0-1): ä½ä¿¡å¿ƒåº¦æ–‡å­—å€åŸŸé–¾å€¼\n",
    "   - é™ä½ â†’ æª¢æ¸¬æ›´å¤šæ¨¡ç³Šæ–‡å­—\n",
    "\n",
    "3. link_threshold (0-1): æ–‡å­—é€£æ¥é–¾å€¼\n",
    "   - é™ä½ â†’ æ›´å®¹æ˜“é€£æ¥åˆ†é–‹çš„å­—ç¬¦\n",
    "\n",
    "4. canvas_size: å…§éƒ¨è™•ç†çš„åœ–ç‰‡å¤§å°\n",
    "   - å¢åŠ  â†’ ä¿ç•™æ›´å¤šç´°ç¯€ (ä½†é€Ÿåº¦è®Šæ…¢)\n",
    "\n",
    "5. mag_ratio: åœ–ç‰‡æ”¾å¤§æ¯”ä¾‹\n",
    "   - å¢åŠ  â†’ å°å­—æ›´æ¸…æ™°\n",
    "\n",
    "6. min_size: æœ€å°æ–‡å­—å¤§å° (åƒç´ )\n",
    "   - é™ä½ â†’ æª¢æ¸¬æ›´å°çš„æ–‡å­—\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee565faf",
   "metadata": {},
   "source": [
    "---\n",
    "## æ–¹æ¡ˆ A2: åœ–ç‰‡é è™•ç†å„ªåŒ– (é‡è¦!)\n",
    "\n",
    "é‡å°å°ç£ç™¼ç¥¨çš„ç‰¹æ€§é€²è¡Œé è™•ç†,å¯ä»¥é¡¯è‘—æ”¹å–„è¾¨è­˜ç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902fe2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "åŸå§‹åœ–ç‰‡ OCR\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wing199901/GitHub/SHape/smart-spend-backend/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.64] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³å£¼72è™Ÿèˆ–\n",
      "[0.81] Te1;2495-0822\n",
      "[0.42] T1 Io\n",
      "[1.00] 5\n",
      "[1.00] Cardno\n",
      "[1.00] 800012\n",
      "[0.96] Staff\n",
      "[1.00] ç¶“ç†\n",
      "[0.65] Guest Ilo.\n",
      "[0.61] Date: 2025-09-26\n",
      "[0.49] Time;\n",
      "[0.50] 18;38\n",
      "[0.68] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[0.92] 98.0\n",
      "[0.93] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.71] 18.0\n",
      "[0.99] 17;50\n",
      "[0.84] CO5è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.81] æ»¿]è¾£)\n",
      "[0.83] 78.0\n",
      "[0.86] 17;50 D08æŸ´èœå·é£¯\n",
      "[0.82] 62.0\n",
      "[0.90] Sub Tota1\n",
      "[0.59] 315.0\n",
      "[0.98] (0000119183)\n",
      "[0.62] 10% Service:\n",
      "[0.66] 31,60\n",
      "[0.54] Tota1\n",
      "[0.80] $348.0\n",
      "[0.81] Tota1\n",
      "[0.99] $348.0\n",
      "[1.00] Cash\n",
      "[1.00] $348.0\n",
      "[0.97] Helcome\n",
      "\n",
      "============================================================\n",
      "é è™•ç†å¾Œ OCR (ä½¿ç”¨ CLAHE å¢å¼·)\n",
      "============================================================\n",
      "[0.70] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[0.44] ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è€‹è‡º72è™Ÿèˆ–\n",
      "[0.51] Te1 :2495-0822\n",
      "[0.49] T1 No\n",
      "[1.00] 5\n",
      "[0.84] Cardno\n",
      "[1.00] 800012\n",
      "[1.00] Staff\n",
      "[1.00] ç¶“ç†\n",
      "[0.63] Guest Mo.\n",
      "[0.65] Date: 2025-09-26\n",
      "[0.70] Time;\n",
      "[0.68] 18;38\n",
      "[0.53] 17;50 C01ç‰›éª¨æ¹¯é£¯\n",
      "[0.99] 98.0\n",
      "[0.92] 17;50 C04è¾£æ³¡èœæ¹¯é£¯\n",
      "[0.63] 78.0\n",
      "[0.96] 17;50 C05è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[1.00] æ»¿]è¾£)\n",
      "[0.76] 18.0\n",
      "[0.90] 17;50 D08æŸ´èœå·é£¯\n",
      "[0.96] 62.0\n",
      "[0.85] Sub Tota1\n",
      "[0.94] 316.0\n",
      "[1.00] (0000119183)\n",
      "[0.76] 10 Service:\n",
      "[0.78] 31.60\n",
      "[0.70] Tota1\n",
      "[0.99] $348.0\n",
      "[0.68] Tota1\n",
      "[0.98] $348.0\n",
      "[1.00] Cash\n",
      "[0.92] $348.0\n",
      "[0.77] Welcome\n",
      "\n",
      "============================================================\n",
      "é è™•ç†å¾Œ OCR (ä½¿ç”¨éŠ³åŒ–)\n",
      "============================================================\n",
      "[0.98] éŸ“é¤éŸ“åœ‹æ–™ç†\n",
      "[1.00] 5\n",
      "[0.40] 8o0012\n",
      "[0.54] ime; 18;38\n",
      "[0.40] 78.0\n",
      "[0.44] 17;50 005è»Ÿæ»‘è±†è…æµ·é®®æ¹¯\n",
      "[0.72] æ»¿è¾£\n",
      "[0.88] 62.0\n",
      "[0.58] Sup Total\n",
      "[0.67] 316.0\n",
      "[0.58] (0000119183)\n",
      "[0.41] 31.6(\n",
      "[0.85] Total\n",
      "[1.00] $348.0\n",
      "[0.72] Total\n",
      "[0.57] $348.(\n",
      "[0.86] Cash\n",
      "[0.91] $348.0\n",
      "[0.90] Helcoe\n",
      "\n",
      "============================================================\n",
      "é è™•ç†å¾Œ OCR (ä½¿ç”¨äºŒå€¼åŒ–)\n",
      "============================================================\n",
      "[0.60] $3483\n",
      "[0.53] $348\n",
      "\n",
      "é è™•ç†åœ–ç‰‡å·²ä¿å­˜è‡³ ./output/ è³‡æ–™å¤¾\n"
     ]
    }
   ],
   "source": [
    "# æ–¹æ¡ˆ A2: é‡å°ç™¼ç¥¨çš„åœ–ç‰‡é è™•ç†\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "def preprocess_receipt(image_path):\n",
    "    \"\"\"é‡å°å°ç£ç™¼ç¥¨å„ªåŒ–çš„é è™•ç†æµç¨‹\"\"\"\n",
    "    \n",
    "    # è®€å–åœ–ç‰‡\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # 1. è½‰ç°éš\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. å»å™ª - ä½¿ç”¨é›™é‚Šæ¿¾æ³¢å™¨ä¿ç•™é‚Šç·£\n",
    "    denoised = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    \n",
    "    # 3. å°æ¯”åº¦å¢å¼· - CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    # 4. éŠ³åŒ–\n",
    "    kernel_sharpening = np.array([[-1,-1,-1],\n",
    "                                   [-1, 9,-1],\n",
    "                                   [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(enhanced, -1, kernel_sharpening)\n",
    "    \n",
    "    # 5. è‡ªé©æ‡‰äºŒå€¼åŒ–\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        sharpened,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        11,  # block size\n",
    "        2    # C constant\n",
    "    )\n",
    "    \n",
    "    return img, gray, denoised, enhanced, sharpened, binary\n",
    "\n",
    "# æ¸¬è©¦é è™•ç†æ•ˆæœ\n",
    "image_path = './samples/2.jpeg'\n",
    "reader = easyocr.Reader(['ch_tra', 'en'], gpu=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"åŸå§‹åœ–ç‰‡ OCR\")\n",
    "print(\"=\"*60)\n",
    "result_original = reader.readtext(image_path, detail=1)\n",
    "for bbox, text, conf in result_original:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "# é è™•ç†å¾Œæ¸¬è©¦\n",
    "img, gray, denoised, enhanced, sharpened, binary = preprocess_receipt(image_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é è™•ç†å¾Œ OCR (ä½¿ç”¨ CLAHE å¢å¼·)\")\n",
    "print(\"=\"*60)\n",
    "result_enhanced = reader.readtext(enhanced, detail=1)\n",
    "for bbox, text, conf in result_enhanced:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é è™•ç†å¾Œ OCR (ä½¿ç”¨éŠ³åŒ–)\")\n",
    "print(\"=\"*60)\n",
    "result_sharpened = reader.readtext(sharpened, detail=1)\n",
    "for bbox, text, conf in result_sharpened:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é è™•ç†å¾Œ OCR (ä½¿ç”¨äºŒå€¼åŒ–)\")\n",
    "print(\"=\"*60)\n",
    "result_binary = reader.readtext(binary, detail=1)\n",
    "for bbox, text, conf in result_binary:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "# ä¿å­˜é è™•ç†çµæœä¾›è¦–è¦ºæª¢æŸ¥\n",
    "cv2.imwrite('./output/preprocessed_enhanced.jpeg', enhanced)\n",
    "cv2.imwrite('./output/preprocessed_sharpened.jpeg', sharpened)\n",
    "cv2.imwrite('./output/preprocessed_binary.jpeg', binary)\n",
    "\n",
    "print(\"\\né è™•ç†åœ–ç‰‡å·²ä¿å­˜è‡³ ./output/ è³‡æ–™å¤¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bac774",
   "metadata": {},
   "source": [
    "---\n",
    "## æ–¹æ¡ˆ A3: çµæœå¾Œè™•ç†èˆ‡éŒ¯èª¤ä¿®æ­£\n",
    "\n",
    "é‡å°å¸¸è¦‹çš„è¾¨è­˜éŒ¯èª¤é€²è¡Œè‡ªå‹•ä¿®æ­£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ A3: OCR çµæœå¾Œè™•ç†èˆ‡éŒ¯èª¤ä¿®æ­£\n",
    "\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# 1. å¸¸è¦‹çš„ OCR è¾¨è­˜éŒ¯èª¤å°ç…§è¡¨ (é‡å°å°ç£ç™¼ç¥¨)\n",
    "COMMON_ERRORS = {\n",
    "    # æ•¸å­—å®¹æ˜“è¾¨è­˜éŒ¯èª¤\n",
    "    'O': '0',  # è‹±æ–‡ O â†’ æ•¸å­— 0\n",
    "    'o': '0',\n",
    "    'I': '1',  # è‹±æ–‡ I â†’ æ•¸å­— 1\n",
    "    'l': '1',  # å°å¯« L â†’ æ•¸å­— 1\n",
    "    'S': '5',\n",
    "    's': '5',\n",
    "    'Z': '2',\n",
    "    'B': '8',\n",
    "    \n",
    "    # ä¸­æ–‡å­—å®¹æ˜“è¾¨è­˜éŒ¯èª¤\n",
    "    'è¾¨': 'è¾¦',\n",
    "    'è­˜': 'è®¤',\n",
    "}\n",
    "\n",
    "# 2. å°ç£ç™¼ç¥¨å¸¸è¦‹é—œéµå­—å­—å…¸ (ç”¨æ–¼ä¿¡å¿ƒåº¦ä½çš„çµæœ)\n",
    "RECEIPT_KEYWORDS = [\n",
    "    'çµ±ä¸€ç·¨è™Ÿ', 'ç™¼ç¥¨è™Ÿç¢¼', 'éš¨æ©Ÿç¢¼', 'ç¸½è¨ˆ', 'ç‡Ÿæ¥­äºº', \n",
    "    'è²·å—äºº', 'æ—¥æœŸ', 'æ™‚é–“', 'å“å', 'æ•¸é‡', 'å–®åƒ¹', 'é‡‘é¡',\n",
    "    'å°è¨ˆ', 'åˆè¨ˆ', 'æ‡‰ç¨…', 'å…ç¨…', 'èª²ç¨…åˆ¥', 'ç¨…é¡',\n",
    "    'é›»å­ç™¼ç¥¨', 'è¼‰å…·', 'QR Code'\n",
    "]\n",
    "\n",
    "# 3. æ•¸å­—æ ¼å¼ä¿®æ­£ (ç™¼ç¥¨è™Ÿç¢¼ã€é‡‘é¡ç­‰)\n",
    "def fix_invoice_number(text):\n",
    "    \"\"\"ä¿®æ­£ç™¼ç¥¨è™Ÿç¢¼æ ¼å¼ (å…©å€‹è‹±æ–‡å­—æ¯ + 8ä½æ•¸å­—)\"\"\"\n",
    "    # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šç¬¦è™Ÿ\n",
    "    cleaned = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "    \n",
    "    # åŒ¹é…æ ¼å¼: XX-12345678 æˆ– XX12345678\n",
    "    match = re.match(r'([A-Z]{2})(\\d{8})', cleaned)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}-{match.group(2)}\"\n",
    "    return text\n",
    "\n",
    "def fix_amount(text):\n",
    "    \"\"\"ä¿®æ­£é‡‘é¡æ ¼å¼\"\"\"\n",
    "    # ç§»é™¤éæ•¸å­—å’Œå°æ•¸é»\n",
    "    cleaned = re.sub(r'[^\\d.]', '', text)\n",
    "    \n",
    "    # ç¢ºä¿åªæœ‰ä¸€å€‹å°æ•¸é»\n",
    "    parts = cleaned.split('.')\n",
    "    if len(parts) > 2:\n",
    "        cleaned = parts[0] + '.' + ''.join(parts[1:])\n",
    "    \n",
    "    try:\n",
    "        return f\"${float(cleaned):,.0f}\"\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def fix_date(text):\n",
    "    \"\"\"ä¿®æ­£æ—¥æœŸæ ¼å¼\"\"\"\n",
    "    # åŒ¹é…å¸¸è¦‹æ—¥æœŸæ ¼å¼\n",
    "    match = re.search(r'(\\d{3,4})[å¹´/-]?(\\d{1,2})[æœˆ/-]?(\\d{1,2})', text)\n",
    "    if match:\n",
    "        year, month, day = match.groups()\n",
    "        # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´\n",
    "        if len(year) == 3:\n",
    "            year = str(int(year) + 1911)\n",
    "        return f\"{year}/{month.zfill(2)}/{day.zfill(2)}\"\n",
    "    return text\n",
    "\n",
    "def correct_ocr_result(text, confidence):\n",
    "    \"\"\"\n",
    "    ç¶œåˆä¿®æ­£ OCR çµæœ\n",
    "    \n",
    "    Args:\n",
    "        text: OCR è¾¨è­˜å‡ºçš„æ–‡å­—\n",
    "        confidence: ä¿¡å¿ƒåº¦\n",
    "    \n",
    "    Returns:\n",
    "        ä¿®æ­£å¾Œçš„æ–‡å­—\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. å¦‚æœä¿¡å¿ƒåº¦å¾ˆé«˜ (>0.9),ç›´æ¥è¿”å›\n",
    "    if confidence > 0.9:\n",
    "        return text\n",
    "    \n",
    "    # 2. å¸¸è¦‹éŒ¯èª¤æ›¿æ›\n",
    "    corrected = text\n",
    "    for wrong, correct in COMMON_ERRORS.items():\n",
    "        corrected = corrected.replace(wrong, correct)\n",
    "    \n",
    "    # 3. å˜—è©¦åŒ¹é…é—œéµå­— (ä¿¡å¿ƒåº¦ < 0.7)\n",
    "    if confidence < 0.7:\n",
    "        matches = get_close_matches(corrected, RECEIPT_KEYWORDS, n=1, cutoff=0.6)\n",
    "        if matches:\n",
    "            corrected = matches[0]\n",
    "    \n",
    "    # 4. æ ¼å¼ç‰¹å®šä¿®æ­£\n",
    "    if re.search(r'[A-Z]{2}.*\\d{8}', corrected):\n",
    "        corrected = fix_invoice_number(corrected)\n",
    "    elif re.search(r'\\d+[å…ƒ$]?', corrected):\n",
    "        corrected = fix_amount(corrected)\n",
    "    elif 'å¹´' in corrected or 'æœˆ' in corrected:\n",
    "        corrected = fix_date(corrected)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "# æ¸¬è©¦å¾Œè™•ç†æ•ˆæœ\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['ch_tra', 'en'], gpu=False)\n",
    "image_path = './samples/2.jpeg'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"åŸå§‹ OCR çµæœ\")\n",
    "print(\"=\"*60)\n",
    "results = reader.readtext(image_path, detail=1)\n",
    "for bbox, text, conf in results:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¾Œè™•ç†ä¿®æ­£å¾Œ\")\n",
    "print(\"=\"*60)\n",
    "for bbox, text, conf in results:\n",
    "    if conf > 0.3:\n",
    "        corrected = correct_ocr_result(text, conf)\n",
    "        if text != corrected:\n",
    "            print(f\"[{conf:.2f}] {text} â†’ {corrected} âœ“\")\n",
    "        else:\n",
    "            print(f\"[{conf:.2f}] {corrected}\")\n",
    "\n",
    "# 5. ä¿¡å¿ƒåº¦éæ¿¾\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é«˜ä¿¡å¿ƒåº¦çµæœ (>0.7)\")\n",
    "print(\"=\"*60)\n",
    "high_conf_results = [(bbox, correct_ocr_result(text, conf), conf) \n",
    "                     for bbox, text, conf in results if conf > 0.7]\n",
    "for bbox, text, conf in high_conf_results:\n",
    "    print(f\"[{conf:.2f}] {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e939a26",
   "metadata": {},
   "source": [
    "---\n",
    "## æ–¹æ¡ˆ A4: å¤šæ¨¡å‹æ•´åˆ (Ensemble)\n",
    "\n",
    "çµåˆå¤šå€‹ OCR å¼•æ“çš„çµæœ,æé«˜æº–ç¢ºç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ A4: å¤š OCR å¼•æ“æ•´åˆ\n",
    "\n",
    "import easyocr\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def ocr_ensemble(image_path, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    æ•´åˆå¤šå€‹ OCR å¼•æ“çš„çµæœ\n",
    "    \n",
    "    ç­–ç•¥:\n",
    "    1. ä½¿ç”¨ EasyOCR å’Œ DocTR å…©å€‹å¼•æ“\n",
    "    2. æ¯”è¼ƒå…©å€‹å¼•æ“çš„çµæœ\n",
    "    3. è‹¥çµæœä¸€è‡´ â†’ é«˜ä¿¡å¿ƒåº¦\n",
    "    4. è‹¥çµæœä¸ä¸€è‡´ â†’ é¸æ“‡ä¿¡å¿ƒåº¦è¼ƒé«˜çš„\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. EasyOCR çµæœ\n",
    "    print(\"æ­£åœ¨åŸ·è¡Œ EasyOCR...\")\n",
    "    reader = easyocr.Reader(['ch_tra', 'en'], gpu=False)\n",
    "    easyocr_results = reader.readtext(image_path, detail=1)\n",
    "    \n",
    "    results['easyocr'] = []\n",
    "    for bbox, text, conf in easyocr_results:\n",
    "        if conf > confidence_threshold:\n",
    "            results['easyocr'].append({\n",
    "                'text': text,\n",
    "                'confidence': conf,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "    \n",
    "    # 2. DocTR çµæœ\n",
    "    print(\"æ­£åœ¨åŸ·è¡Œ DocTR...\")\n",
    "    model = ocr_predictor(pretrained=True)\n",
    "    doc = DocumentFile.from_images(image_path)\n",
    "    doctr_result = model(doc)\n",
    "    \n",
    "    results['doctr'] = []\n",
    "    for page in doctr_result.pages:\n",
    "        for block in page.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    if word.confidence > confidence_threshold:\n",
    "                        results['doctr'].append({\n",
    "                            'text': word.value,\n",
    "                            'confidence': word.confidence,\n",
    "                            'bbox': word.geometry\n",
    "                        })\n",
    "    \n",
    "    # 3. æ•´åˆçµæœ\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"æ•´åˆçµæœåˆ†æ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # çµ±è¨ˆæ¯å€‹æ–‡å­—å‡ºç¾çš„æ¬¡æ•¸å’Œå¹³å‡ä¿¡å¿ƒåº¦\n",
    "    text_stats = defaultdict(lambda: {'count': 0, 'total_conf': 0, 'sources': []})\n",
    "    \n",
    "    for source, items in results.items():\n",
    "        for item in items:\n",
    "            text = item['text'].strip()\n",
    "            text_stats[text]['count'] += 1\n",
    "            text_stats[text]['total_conf'] += item['confidence']\n",
    "            text_stats[text]['sources'].append(source)\n",
    "    \n",
    "    # è¨ˆç®—æœ€çµ‚çµæœ\n",
    "    final_results = []\n",
    "    for text, stats in text_stats.items():\n",
    "        avg_conf = stats['total_conf'] / stats['count']\n",
    "        \n",
    "        # å¦‚æœå…©å€‹å¼•æ“éƒ½è¾¨è­˜å‡ºåŒæ¨£çš„æ–‡å­— â†’ é«˜ä¿¡å¿ƒåº¦\n",
    "        boost_factor = 1.2 if stats['count'] > 1 else 1.0\n",
    "        final_conf = min(avg_conf * boost_factor, 1.0)\n",
    "        \n",
    "        final_results.append({\n",
    "            'text': text,\n",
    "            'confidence': final_conf,\n",
    "            'agreement': stats['count'] > 1,\n",
    "            'sources': stats['sources']\n",
    "        })\n",
    "    \n",
    "    # ä¾ä¿¡å¿ƒåº¦æ’åº\n",
    "    final_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    return final_results, results\n",
    "\n",
    "# åŸ·è¡Œæ•´åˆ\n",
    "image_path = './samples/2.jpeg'\n",
    "final_results, raw_results = ocr_ensemble(image_path, confidence_threshold=0.5)\n",
    "\n",
    "# é¡¯ç¤ºå„å¼•æ“åŸå§‹çµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EasyOCR åŸå§‹çµæœ\")\n",
    "print(\"=\"*60)\n",
    "for item in raw_results['easyocr']:\n",
    "    print(f\"[{item['confidence']:.2f}] {item['text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DocTR åŸå§‹çµæœ\")\n",
    "print(\"=\"*60)\n",
    "for item in raw_results['doctr']:\n",
    "    print(f\"[{item['confidence']:.2f}] {item['text']}\")\n",
    "\n",
    "# é¡¯ç¤ºæ•´åˆå¾Œçµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ•´åˆå¾Œçš„æœ€çµ‚çµæœ\")\n",
    "print(\"=\"*60)\n",
    "for item in final_results:\n",
    "    agreement_mark = \"âœ“âœ“\" if item['agreement'] else \"âœ“\"\n",
    "    sources = \"+\".join(item['sources'])\n",
    "    print(f\"[{item['confidence']:.2f}] {agreement_mark} {item['text']} ({sources})\")\n",
    "\n",
    "# åªé¡¯ç¤ºé«˜ä¿¡å¿ƒåº¦ (>0.7) ä¸”å…©å€‹å¼•æ“éƒ½èªåŒçš„çµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é«˜ä¿¡å¿ƒåº¦ä¸”é›™å¼•æ“èªåŒçš„çµæœ (æœ€å¯é )\")\n",
    "print(\"=\"*60)\n",
    "reliable_results = [r for r in final_results if r['confidence'] > 0.7 and r['agreement']]\n",
    "for item in reliable_results:\n",
    "    print(f\"[{item['confidence']:.2f}] {item['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8c7b3",
   "metadata": {},
   "source": [
    "---\n",
    "## æ–¹æ¡ˆ B: Fine-tuning (å¾®èª¿ç¾æœ‰æ¨¡å‹)\n",
    "\n",
    "âš ï¸ **é›£åº¦: ä¸­ç­‰** | éœ€è¦ä¸€äº›æ¨™è¨»è³‡æ–™ (50-200 å¼µ) | è¨“ç·´æ™‚é–“: æ•¸å°æ™‚\n",
    "\n",
    "å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½ç„¡æ³•é”åˆ°ç†æƒ³æ•ˆæœ,å¯ä»¥è€ƒæ…®å¾®èª¿ EasyOCR çš„ç¾æœ‰æ¨¡å‹ã€‚\n",
    "\n",
    "### å„ªé»\n",
    "- æ¯”å¾é ­è¨“ç·´å¿«å¾—å¤š\n",
    "- éœ€è¦çš„è³‡æ–™é‡è¼ƒå°‘\n",
    "- å¯ä»¥é‡å°ç‰¹å®šé ˜åŸŸ (å°ç£ç™¼ç¥¨) å„ªåŒ–\n",
    "\n",
    "### æ­¥é©Ÿæ¦‚è¿°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ B: Fine-tuning æº–å‚™å·¥ä½œ\n",
    "\n",
    "\"\"\"\n",
    "EasyOCR Fine-tuning æµç¨‹:\n",
    "\n",
    "1. æº–å‚™è³‡æ–™é›†\n",
    "   - æ”¶é›† 50-200 å¼µç™¼ç¥¨åœ–ç‰‡\n",
    "   - æ¨™è¨»æ­£ç¢ºçš„æ–‡å­—ä½ç½®å’Œå…§å®¹\n",
    "   - æ ¼å¼: åœ–ç‰‡ + å°æ‡‰çš„æ–‡å­—æ¨™è¨» (JSON æˆ– TXT)\n",
    "\n",
    "2. ä½¿ç”¨ EasyOCR çš„è¨“ç·´è…³æœ¬\n",
    "   - GitHub: https://github.com/JaidedAI/EasyOCR\n",
    "   - éœ€è¦ PyTorch å’Œ GPU\n",
    "\n",
    "3. è¨“ç·´åƒæ•¸èª¿æ•´\n",
    "   - Learning rate: 0.0001 (è¼ƒå°,é¿å…ç ´å£é è¨“ç·´æ¬Šé‡)\n",
    "   - Batch size: 8-16\n",
    "   - Epochs: 10-50\n",
    "   - Early stopping\n",
    "\n",
    "4. è©•ä¼°å’Œæ¸¬è©¦\n",
    "\"\"\"\n",
    "\n",
    "# è³‡æ–™æ¨™è¨»å·¥å…·æ¨è–¦\n",
    "print(\"=\"*60)\n",
    "print(\"è³‡æ–™æ¨™è¨»å·¥å…·æ¨è–¦\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. **Label Studio** (æ¨è–¦)\n",
    "   - ç¶²å€: https://labelstud.io/\n",
    "   - å…è²»é–‹æº\n",
    "   - æ”¯æ´ OCR æ¨™è¨»\n",
    "   - å¯åŒ¯å‡ºå¤šç¨®æ ¼å¼\n",
    "   \n",
    "   å®‰è£:\n",
    "   pip install label-studio\n",
    "   label-studio start\n",
    "\n",
    "2. **CVAT** (Computer Vision Annotation Tool)\n",
    "   - ç¶²å€: https://www.cvat.ai/\n",
    "   - Intel é–‹ç™¼\n",
    "   - æ”¯æ´æ–‡å­—è¾¨è­˜æ¨™è¨»\n",
    "   \n",
    "3. **LabelImg**\n",
    "   - ç°¡å–®æ˜“ç”¨\n",
    "   - é©åˆå°è¦æ¨¡æ¨™è¨»\n",
    "   \n",
    "   å®‰è£:\n",
    "   pip install labelImg\n",
    "   labelImg\n",
    "\n",
    "4. **MakeSense.ai**\n",
    "   - ç¶²å€: https://www.makesense.ai/\n",
    "   - ç·šä¸Šå·¥å…·,ç„¡éœ€å®‰è£\n",
    "   - é©åˆå¿«é€Ÿæ¨™è¨»\n",
    "\"\"\")\n",
    "\n",
    "# è³‡æ–™é›†æ ¼å¼ç¯„ä¾‹\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è³‡æ–™é›†æ ¼å¼ç¯„ä¾‹\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "è³‡æ–™å¤¾çµæ§‹:\n",
    "dataset/\n",
    "â”œâ”€â”€ images/\n",
    "â”‚   â”œâ”€â”€ receipt_001.jpg\n",
    "â”‚   â”œâ”€â”€ receipt_002.jpg\n",
    "â”‚   â””â”€â”€ ...\n",
    "â””â”€â”€ labels/\n",
    "    â”œâ”€â”€ receipt_001.txt\n",
    "    â”œâ”€â”€ receipt_002.txt\n",
    "    â””â”€â”€ ...\n",
    "\n",
    "æ¨™è¨»æª”æ¡ˆæ ¼å¼ (receipt_001.txt):\n",
    "x1,y1,x2,y2,x3,y3,x4,y4,text\n",
    "100,50,300,50,300,80,100,80,çµ±ä¸€ç·¨è™Ÿ\n",
    "100,90,300,90,300,120,100,120,12345678\n",
    "...\n",
    "\n",
    "æˆ–ä½¿ç”¨ JSON æ ¼å¼:\n",
    "{\n",
    "  \"image\": \"receipt_001.jpg\",\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"bbox\": [[100,50], [300,50], [300,80], [100,80]],\n",
    "      \"text\": \"çµ±ä¸€ç·¨è™Ÿ\",\n",
    "      \"confidence\": 1.0\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# å¿«é€Ÿæ¨™è¨»æŠ€å·§\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¿«é€Ÿæ¨™è¨»æŠ€å·§\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. **å…ˆç”¨ EasyOCR é æ¨™è¨»**\n",
    "   - ç”¨ç¾æœ‰æ¨¡å‹è¾¨è­˜\n",
    "   - åªä¿®æ­£éŒ¯èª¤çš„éƒ¨åˆ†\n",
    "   - ç¯€çœå¤§é‡æ™‚é–“\n",
    "\n",
    "2. **åªæ¨™è¨»å¸¸è¦‹éŒ¯èª¤å€åŸŸ**\n",
    "   - ä¸éœ€è¦æ¨™è¨»æ•´å¼µç™¼ç¥¨\n",
    "   - å°ˆæ³¨æ–¼å®¹æ˜“è¾¨è­˜éŒ¯èª¤çš„å­—æ®µ\n",
    "   - ä¾‹å¦‚: é‡‘é¡ã€æ—¥æœŸã€çµ±ç·¨\n",
    "\n",
    "3. **ä½¿ç”¨æ¨¡æ¿**\n",
    "   - å°ç£ç™¼ç¥¨æ ¼å¼ç›¸å°å›ºå®š\n",
    "   - å»ºç«‹æ¨¡æ¿å¿«é€Ÿæ¨™è¨»\n",
    "\"\"\")\n",
    "\n",
    "# é æ¨™è¨»è…³æœ¬ç¯„ä¾‹\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é æ¨™è¨»è…³æœ¬ç¯„ä¾‹ (ç¯€çœæ¨™è¨»æ™‚é–“)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import easyocr\n",
    "import json\n",
    "import os\n",
    "\n",
    "def pre_annotate_images(image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ EasyOCR é æ¨™è¨»åœ–ç‰‡\n",
    "    äººå·¥åªéœ€è¦æª¢æŸ¥å’Œä¿®æ­£éŒ¯èª¤\n",
    "    \"\"\"\n",
    "    \n",
    "    reader = easyocr.Reader(['ch_tra', 'en'], gpu=False)\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if not image_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        results = reader.readtext(image_path, detail=1)\n",
    "        \n",
    "        annotations = []\n",
    "        for bbox, text, conf in results:\n",
    "            annotations.append({\n",
    "                'bbox': [[int(x), int(y)] for x, y in bbox],\n",
    "                'text': text,\n",
    "                'confidence': float(conf)\n",
    "            })\n",
    "        \n",
    "        # å„²å­˜ç‚º JSON\n",
    "        output_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(image_file)[0] + '.json'\n",
    "        )\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'image': image_file,\n",
    "                'annotations': annotations\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"âœ“ å·²é æ¨™è¨»: {image_file} ({len(annotations)} å€‹æ–‡å­—å€åŸŸ)\")\n",
    "\n",
    "print(\"\"\"\n",
    "ä½¿ç”¨æ–¹å¼:\n",
    "pre_annotate_images('./dataset/images', './dataset/pre_labels')\n",
    "\n",
    "ç„¶å¾Œä½¿ç”¨ Label Studio æˆ–å…¶ä»–å·¥å…·é–‹å•Ÿé æ¨™è¨»çµæœ,\n",
    "åªéœ€è¦ä¿®æ­£éŒ¯èª¤çš„éƒ¨åˆ†å³å¯!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9404c8c",
   "metadata": {},
   "source": [
    "---\n",
    "## æ–¹æ¡ˆ C: å¾é ­è¨“ç·´ (å®Œæ•´è¨“ç·´æµç¨‹)\n",
    "\n",
    "âš ï¸ **é›£åº¦: éå¸¸é«˜** | éœ€è¦å¤§é‡æ¨™è¨»è³‡æ–™ (1000+ å¼µ) | è¨“ç·´æ™‚é–“: æ•¸å¤©åˆ°æ•¸é€± | éœ€è¦å¼·å¤§ GPU\n",
    "\n",
    "**é™¤éè¬ä¸å¾—å·²,å¦å‰‡ä¸å»ºè­°ä½¿ç”¨æ­¤æ–¹æ¡ˆ!**\n",
    "\n",
    "æ–¹æ¡ˆ A (åƒæ•¸å„ªåŒ– + é è™•ç† + å¾Œè™•ç†) é€šå¸¸å·²ç¶“å¯ä»¥è§£æ±º 90% çš„å•é¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd40fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ C: å®Œæ•´è¨“ç·´æµç¨‹åƒè€ƒ\n",
    "\n",
    "\"\"\"\n",
    "EasyOCR å®Œæ•´è¨“ç·´æµç¨‹ (åƒ…ä¾›åƒè€ƒ,éå¸¸è¤‡é›œ!)\n",
    "\n",
    "âš ï¸ é‡è¦æé†’:\n",
    "1. éœ€è¦ 1000+ å¼µæ¨™è¨»å¥½çš„åœ–ç‰‡\n",
    "2. éœ€è¦å¼·å¤§çš„ GPU (è‡³å°‘ RTX 3090 æˆ–æ›´å¥½)\n",
    "3. è¨“ç·´æ™‚é–“: æ•¸å¤©åˆ°æ•¸é€±\n",
    "4. éœ€è¦æ·±å…¥äº†è§£ PyTorch å’Œæ·±åº¦å­¸ç¿’\n",
    "5. æˆæœ¬éå¸¸é«˜æ˜‚\n",
    "\n",
    "å»ºè­°: å¦‚æœé ç®—å…è¨±,ç›´æ¥ä½¿ç”¨é›²ç«¯ OCR API æœå‹™!\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"å®Œæ•´è¨“ç·´æ‰€éœ€è³‡æº\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "ç¡¬é«”éœ€æ±‚:\n",
    "- GPU: RTX 3090 (24GB) æˆ–ä»¥ä¸Š\n",
    "- RAM: 32GB+\n",
    "- å„²å­˜ç©ºé–“: 100GB+\n",
    "\n",
    "è»Ÿé«”éœ€æ±‚:\n",
    "- Python 3.8+\n",
    "- PyTorch 1.10+\n",
    "- CUDA 11.3+\n",
    "- EasyOCR åŸå§‹ç¢¼\n",
    "\n",
    "è³‡æ–™éœ€æ±‚:\n",
    "- è¨“ç·´é›†: 1000+ å¼µæ¨™è¨»åœ–ç‰‡\n",
    "- é©—è­‰é›†: 200+ å¼µæ¨™è¨»åœ–ç‰‡\n",
    "- æ¸¬è©¦é›†: 100+ å¼µæ¨™è¨»åœ–ç‰‡\n",
    "\n",
    "æ™‚é–“æˆæœ¬:\n",
    "- è³‡æ–™æ¨™è¨»: 40-80 å°æ™‚\n",
    "- æ¨¡å‹è¨“ç·´: 3-7 å¤©\n",
    "- èª¿åƒå’Œå„ªåŒ–: 1-2 é€±\n",
    "\n",
    "é‡‘éŒ¢æˆæœ¬:\n",
    "- GPU ç§Ÿç”¨: $500-2000\n",
    "- äººåŠ›æˆæœ¬: $2000-5000\n",
    "- ç¸½è¨ˆ: $2500-7000+\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è¨“ç·´æ­¥é©Ÿ (æ¦‚è¿°)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. æº–å‚™ç’°å¢ƒ\n",
    "   git clone https://github.com/JaidedAI/EasyOCR.git\n",
    "   cd EasyOCR\n",
    "   pip install -r requirements.txt\n",
    "\n",
    "2. æº–å‚™è³‡æ–™é›†\n",
    "   - æ ¼å¼è½‰æ›\n",
    "   - è³‡æ–™å¢å¼·\n",
    "   - è¨“ç·´/é©—è­‰/æ¸¬è©¦é›†åˆ†å‰²\n",
    "\n",
    "3. ä¿®æ”¹é…ç½®æª”æ¡ˆ\n",
    "   - èªè¨€è¨­å®š\n",
    "   - æ¨¡å‹æ¶æ§‹\n",
    "   - è¨“ç·´åƒæ•¸\n",
    "\n",
    "4. é–‹å§‹è¨“ç·´\n",
    "   python train.py --config config.yaml\n",
    "\n",
    "5. è©•ä¼°æ¨¡å‹\n",
    "   python eval.py --model_path ./saved_models/best.pth\n",
    "\n",
    "6. å°å‡ºæ¨¡å‹\n",
    "   python export.py --model_path ./saved_models/best.pth\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ›¿ä»£æ–¹æ¡ˆ - ä½¿ç”¨é›²ç«¯ OCR API (æ¨è–¦!)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "å¦‚æœéœ€è¦æ›´é«˜çš„æº–ç¢ºç‡,å»ºè­°ä½¿ç”¨å°ˆæ¥­çš„ OCR API æœå‹™:\n",
    "\n",
    "1. **Google Cloud Vision API**\n",
    "   - å„ªé»: æº–ç¢ºç‡æ¥µé«˜,æ”¯æ´ç¹é«”ä¸­æ–‡\n",
    "   - åƒ¹æ ¼: $1.5 / 1000 æ¬¡ (å‰ 1000 æ¬¡å…è²»)\n",
    "   - ç¶²å€: https://cloud.google.com/vision\n",
    "\n",
    "2. **Azure Computer Vision**\n",
    "   - å„ªé»: å¾®è»ŸæŠ€è¡“,æº–ç¢ºç‡é«˜\n",
    "   - åƒ¹æ ¼: $1 / 1000 æ¬¡ (å‰ 5000 æ¬¡å…è²»)\n",
    "   - ç¶²å€: https://azure.microsoft.com/services/cognitive-services/computer-vision/\n",
    "\n",
    "3. **AWS Textract**\n",
    "   - å„ªé»: å°ˆé–€é‡å°æ–‡ä»¶è¨­è¨ˆ\n",
    "   - åƒ¹æ ¼: $1.5 / 1000 é \n",
    "   - ç¶²å€: https://aws.amazon.com/textract/\n",
    "\n",
    "4. **ä¸­è¯é›»ä¿¡ OCR API** (å°ç£æœ¬åœ°)\n",
    "   - å„ªé»: é‡å°å°ç£ç™¼ç¥¨å„ªåŒ–\n",
    "   - éœ€è¦æ´½è©¢å ±åƒ¹\n",
    "   \n",
    "æ€§åƒ¹æ¯”åˆ†æ:\n",
    "- è‡ªå·±è¨“ç·´: $2500-7000 (ä¸€æ¬¡æ€§)\n",
    "- ä½¿ç”¨ API: æ¯æœˆ 1000 å¼µ = $1.5/æœˆ\n",
    "\n",
    "å»ºè­°: \n",
    "å¦‚æœæ¯æœˆè™•ç†é‡ < 50è¬å¼µ,ä½¿ç”¨ API æ›´åˆ’ç®—!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç¸½çµèˆ‡å»ºè­°\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "æ¨è–¦çš„æ”¹å–„æµç¨‹:\n",
    "\n",
    "1. å…ˆè©¦ æ–¹æ¡ˆ A1-A4 (åƒæ•¸èª¿å„ª + é è™•ç† + å¾Œè™•ç† + Ensemble)\n",
    "   â”œâ”€ æˆæœ¬: å¹¾ä¹ç‚ºé›¶\n",
    "   â”œâ”€ æ™‚é–“: æ•¸å°æ™‚\n",
    "   â””â”€ æ•ˆæœ: å¯æ”¹å–„ 70-80% çš„è¾¨è­˜éŒ¯èª¤\n",
    "\n",
    "2. å¦‚æœé‚„ä¸å¤ ,è©¦ æ–¹æ¡ˆ B (Fine-tuning)\n",
    "   â”œâ”€ æˆæœ¬: $500-1000\n",
    "   â”œâ”€ æ™‚é–“: 1-2 é€±\n",
    "   â””â”€ æ•ˆæœ: å¯æ”¹å–„ 90-95% çš„è¾¨è­˜éŒ¯èª¤\n",
    "\n",
    "3. å¦‚æœä»ä¸æ»¿æ„,è€ƒæ…®é›²ç«¯ OCR API\n",
    "   â”œâ”€ æˆæœ¬: $1-2 / 1000 æ¬¡\n",
    "   â”œâ”€ æ™‚é–“: ç«‹å³å¯ç”¨\n",
    "   â””â”€ æ•ˆæœ: æº–ç¢ºç‡ 95-99%\n",
    "\n",
    "4. æœ€å¾Œæ‰è€ƒæ…® æ–¹æ¡ˆ C (å®Œæ•´è¨“ç·´)\n",
    "   â”œâ”€ æˆæœ¬: $2500-7000+\n",
    "   â”œâ”€ æ™‚é–“: 1-2 å€‹æœˆ\n",
    "   â””â”€ æ•ˆæœ: å–æ±ºæ–¼è³‡æ–™å“è³ª\n",
    "\n",
    "â­ å»ºè­°: å¾æ–¹æ¡ˆ A é–‹å§‹,å¾ªåºæ¼¸é€²!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e0e38",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š å¿«é€Ÿé–‹å§‹æŒ‡å—\n",
    "\n",
    "å»ºè­°æŒ‰ç…§ä»¥ä¸‹é †åºæ¸¬è©¦å„ç¨®æ–¹æ³•:\n",
    "\n",
    "### ç¬¬ä¸€æ­¥: åƒæ•¸å„ªåŒ– (5 åˆ†é˜)\n",
    "åŸ·è¡Œä¸Šé¢çš„ **æ–¹æ¡ˆ A1** ç¨‹å¼ç¢¼,èª¿æ•´ `readtext()` åƒæ•¸\n",
    "\n",
    "### ç¬¬äºŒæ­¥: é è™•ç†å„ªåŒ– (10 åˆ†é˜)\n",
    "åŸ·è¡Œ **æ–¹æ¡ˆ A2** ç¨‹å¼ç¢¼,æ¸¬è©¦ä¸åŒé è™•ç†æ–¹æ³•\n",
    "\n",
    "### ç¬¬ä¸‰æ­¥: å¾Œè™•ç†ä¿®æ­£ (5 åˆ†é˜)\n",
    "åŸ·è¡Œ **æ–¹æ¡ˆ A3** ç¨‹å¼ç¢¼,è‡ªå‹•ä¿®æ­£å¸¸è¦‹éŒ¯èª¤\n",
    "\n",
    "### ç¬¬å››æ­¥: å¤šæ¨¡å‹æ•´åˆ (15 åˆ†é˜)\n",
    "åŸ·è¡Œ **æ–¹æ¡ˆ A4** ç¨‹å¼ç¢¼,çµåˆ EasyOCR + DocTR\n",
    "\n",
    "### è©•ä¼°æ•ˆæœ\n",
    "æ¯”è¼ƒæ”¹å–„å‰å¾Œçš„è¾¨è­˜æº–ç¢ºç‡,å¦‚æœé”åˆ°éœ€æ±‚å°±å®Œæˆäº†!\n",
    "\n",
    "### å¦‚æœé‚„ä¸å¤ \n",
    "è€ƒæ…® **æ–¹æ¡ˆ B** (Fine-tuning) æˆ–ä½¿ç”¨é›²ç«¯ OCR API\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **å°æŠ€å·§**: å»ºè­°å…ˆåœ¨ `test.ipynb` æ¸¬è©¦å„ç¨®æ–¹æ³•,æ‰¾åˆ°æœ€é©åˆçš„çµ„åˆå¾Œå†æ•´åˆåˆ°æ­£å¼ç¨‹å¼ä¸­!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08011151",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ” é‡å°ç‰¹å®šéŒ¯å­—å•é¡Œçš„åˆ†æ\n",
    "\n",
    "### æ‚¨çš„å•é¡Œ: \n",
    "**æ­£ç¢º**: ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³**è‡º**72è™Ÿèˆ–  \n",
    "**éŒ¯èª¤**: ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³**å£¼**72è™Ÿèˆ– æˆ– å¹³**è€‹è‡º**72è™Ÿèˆ–\n",
    "\n",
    "### åŸå› åˆ†æ:\n",
    "é€™æ˜¯ EasyOCR **è¾¨è­˜æ¨¡å‹ (Recognition Model)** çš„å•é¡Œ,è€Œéæ–‡å­—æª¢æ¸¬å•é¡Œã€‚\n",
    "\n",
    "EasyOCR åŒ…å«å…©å€‹éƒ¨åˆ†:\n",
    "1. **CRAFT (æ–‡å­—æª¢æ¸¬)**: æ‰¾å‡ºæ–‡å­—åœ¨å“ªè£¡ âœ… (é€™éƒ¨åˆ†æ²’å•é¡Œ)\n",
    "2. **Recognition Model (å­—ç¬¦è¾¨è­˜)**: è¾¨è­˜æ–‡å­—å…§å®¹ âŒ (é€™éƒ¨åˆ†å‡ºéŒ¯)\n",
    "\n",
    "### EasyOCR å…©å€‹è¨“ç·´æ–‡ä»¶èªªæ˜:\n",
    "\n",
    "#### ğŸ“„ `custom_model.md` - Recognition Model è¨“ç·´\n",
    "- **ç”¨é€”**: è¨“ç·´å­—ç¬¦è¾¨è­˜æ¨¡å‹ (è§£æ±ºæ‚¨çš„å•é¡Œ!)\n",
    "- **è§£æ±º**: \"è‡º\" è¢«èª¤èªç‚º \"å£¼\" æˆ– \"è€‹è‡º\" çš„å•é¡Œ\n",
    "- **è¨“ç·´å·¥å…·**: ä½¿ç”¨ [deep-text-recognition-benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)\n",
    "- **ç¶²è·¯æ¶æ§‹**: None-VGG-BiLSTM-CTC (å¿…é ˆæ˜¯å…¨å·ç©ç¶²è·¯)\n",
    "\n",
    "#### ğŸ“„ `craft/README.md` - CRAFT æ–‡å­—æª¢æ¸¬è¨“ç·´\n",
    "- **ç”¨é€”**: è¨“ç·´æ–‡å­—ä½ç½®æª¢æ¸¬ (æ‚¨ä¸éœ€è¦!)\n",
    "- **è§£æ±º**: æ‰¾ä¸åˆ°æ–‡å­—ã€æ–‡å­—æ¡†ä¸æº–ç¢ºçš„å•é¡Œ\n",
    "- **æ‚¨çš„æƒ…æ³**: æ–‡å­—æª¢æ¸¬æ­£å¸¸,ä¸éœ€è¦è¨“ç·´ CRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70c357",
   "metadata": {},
   "source": [
    "## ğŸ’¡ é‡å° \"è‡º\" å­—çš„è§£æ±ºæ–¹æ¡ˆ\n",
    "\n",
    "### æ–¹æ¡ˆ 1: ä½¿ç”¨å¾Œè™•ç†ä¿®æ­£ (æœ€ç°¡å–®!) â­\n",
    "\n",
    "ç›´æ¥åœ¨ç¨‹å¼ä¸­ä¿®æ­£é€™å€‹å¸¸è¦‹éŒ¯èª¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a397c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ 1: å¾Œè™•ç†ä¿®æ­£ \"è‡º\" å­—éŒ¯èª¤ (æœ€å¿«é€Ÿ!)\n",
    "\n",
    "import easyocr\n",
    "\n",
    "# æ“´å±•éŒ¯èª¤å°ç…§è¡¨,æ–°å¢ \"è‡º\" ç›¸é—œéŒ¯èª¤\n",
    "TAIWAN_CHAR_ERRORS = {\n",
    "    'å£¼': 'è‡º',  # å¸¸è¦‹éŒ¯èª¤ 1\n",
    "    'è€‹': 'è‡º',  # å¸¸è¦‹éŒ¯èª¤ 2 çš„ä¸€éƒ¨åˆ†\n",
    "    'è€‹è‡º': 'è‡º',  # å®Œæ•´éŒ¯èª¤ 2\n",
    "    'å¹³å£¼': 'å¹³è‡º',  # å®Œæ•´è©çµ„ä¿®æ­£\n",
    "    'å¹³è€‹è‡º': 'å¹³è‡º',\n",
    "    'å¹³è€‹': 'å¹³è‡º',\n",
    "}\n",
    "\n",
    "def fix_taiwan_chars(text):\n",
    "    \"\"\"ä¿®æ­£å°ç£å¸¸è¦‹å­—ç¬¦éŒ¯èª¤\"\"\"\n",
    "    corrected = text\n",
    "    \n",
    "    # é€ä¸€æ›¿æ›éŒ¯èª¤å­—ç¬¦\n",
    "    for wrong, correct in TAIWAN_CHAR_ERRORS.items():\n",
    "        corrected = corrected.replace(wrong, correct)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "# æ¸¬è©¦ä¿®æ­£æ•ˆæœ\n",
    "reader = easyocr.Reader(['ch_tra', 'en'], gpu=True)\n",
    "image_path = './samples/2.jpeg'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"åŸå§‹ OCR çµæœ\")\n",
    "print(\"=\"*60)\n",
    "results = reader.readtext(image_path, detail=1)\n",
    "for bbox, text, conf in results:\n",
    "    if conf > 0.3:\n",
    "        print(f\"[{conf:.2f}] {text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ä¿®æ­£ 'è‡º' å­—éŒ¯èª¤å¾Œ\")\n",
    "print(\"=\"*60)\n",
    "for bbox, text, conf in results:\n",
    "    if conf > 0.3:\n",
    "        corrected = fix_taiwan_chars(text)\n",
    "        if text != corrected:\n",
    "            print(f\"[{conf:.2f}] {text} â†’ {corrected} âœ“ (å·²ä¿®æ­£)\")\n",
    "        else:\n",
    "            print(f\"[{conf:.2f}] {corrected}\")\n",
    "\n",
    "# å®Œæ•´åœ°å€ç¯„ä¾‹æ¸¬è©¦\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å®Œæ•´åœ°å€ä¿®æ­£ç¯„ä¾‹\")\n",
    "print(\"=\"*60)\n",
    "test_addresses = [\n",
    "    \"ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³å£¼72è™Ÿèˆ–\",\n",
    "    \"ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è€‹è‡º72è™Ÿèˆ–\",\n",
    "    \"ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è€‹72è™Ÿèˆ–\",\n",
    "]\n",
    "\n",
    "for addr in test_addresses:\n",
    "    corrected = fix_taiwan_chars(addr)\n",
    "    print(f\"åŸå§‹: {addr}\")\n",
    "    print(f\"ä¿®æ­£: {corrected}\")\n",
    "    print(f\"æ­£ç¢º: {'âœ“' if 'å¹³è‡º' in corrected else 'âœ—'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5d140",
   "metadata": {},
   "source": [
    "---\n",
    "### æ–¹æ¡ˆ 2: è¨“ç·´è‡ªè¨‚ Recognition Model (æ ¹æ“š custom_model.md)\n",
    "\n",
    "âš ï¸ **é›£åº¦: é«˜** | éœ€è¦æ¨™è¨»è³‡æ–™ + GPU | è¨“ç·´æ™‚é–“: æ•¸å°æ™‚åˆ°æ•¸å¤©\n",
    "\n",
    "å¦‚æœå¾Œè™•ç†ç„¡æ³•å®Œå…¨è§£æ±º,å¯ä»¥è¨“ç·´è‡ªå·±çš„è¾¨è­˜æ¨¡å‹ã€‚\n",
    "\n",
    "#### ğŸ“‹ è¨“ç·´æµç¨‹ (æ ¹æ“š EasyOCR custom_model.md):\n",
    "\n",
    "1. **æº–å‚™è³‡æ–™é›†**\n",
    "   - æ”¶é›†åŒ…å« \"è‡º\" å­—çš„åœ–ç‰‡ (50-200 å¼µ)\n",
    "   - ä½¿ç”¨ [TextRecognitionDataGenerator](https://github.com/Belval/TextRecognitionDataGenerator) ç”Ÿæˆåˆæˆè³‡æ–™\n",
    "   \n",
    "2. **è¨“ç·´æ¨¡å‹**\n",
    "   - ä½¿ç”¨ [deep-text-recognition-benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)\n",
    "   - æˆ–ä½¿ç”¨ EasyOCR å…§å»ºçš„ [trainer](https://github.com/JaidedAI/EasyOCR/tree/master/trainer)\n",
    "   - ç¶²è·¯æ¶æ§‹: `None-VGG-BiLSTM-CTC`\n",
    "\n",
    "3. **æº–å‚™ä¸‰å€‹æª”æ¡ˆ**\n",
    "   - `yourmodel.pth` (è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡)\n",
    "   - `yourmodel.yaml` (æ¨¡å‹é…ç½®)\n",
    "   - `yourmodel.py` (ç¶²è·¯æ¶æ§‹å®šç¾©)\n",
    "\n",
    "4. **ä½¿ç”¨è‡ªè¨‚æ¨¡å‹**\n",
    "   ```python\n",
    "   reader = easyocr.Reader(['ch_tra', 'en'], recog_network='yourmodel')\n",
    "   ```\n",
    "\n",
    "#### é‡è¦æª”æ¡ˆä½ç½®:\n",
    "- ç¶²è·¯å®šç¾© (`yourmodel.py`) â†’ `~/.EasyOCR/user_network/`\n",
    "- æ¨¡å‹é…ç½® (`yourmodel.yaml`) â†’ `~/.EasyOCR/user_network/`\n",
    "- æ¨¡å‹æ¬Šé‡ (`yourmodel.pth`) â†’ `~/.EasyOCR/model/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹æ¡ˆ 2: æº–å‚™è¨“ç·´ Recognition Model çš„æ­¥é©Ÿ\n",
    "\n",
    "\"\"\"\n",
    "æ ¹æ“š EasyOCR çš„ custom_model.md,é€™è£¡æ˜¯å®Œæ•´çš„è¨“ç·´æµç¨‹\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 1: ç”ŸæˆåŒ…å« 'è‡º' å­—çš„è¨“ç·´è³‡æ–™\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "ä½¿ç”¨ TextRecognitionDataGenerator ç”Ÿæˆåˆæˆè³‡æ–™:\n",
    "\n",
    "å®‰è£:\n",
    "pip install trdg\n",
    "\n",
    "ç”Ÿæˆç¯„ä¾‹:\n",
    "trdg -c 1000 -w 5 -f 64 -t 4 \\\\\n",
    "     -tc '#000000,#888888' \\\\\n",
    "     -b 3 \\\\\n",
    "     -d 3 \\\\\n",
    "     -k 5 \\\\\n",
    "     -rk \\\\\n",
    "     -na 2 \\\\\n",
    "     -l zh \\\\\n",
    "     -i ./custom_dict.txt \\\\\n",
    "     -o ./training_data\n",
    "\n",
    "custom_dict.txt å…§å®¹ç¯„ä¾‹:\n",
    "å¹³è‡º\n",
    "è‡ºç£\n",
    "è‡ºåŒ—\n",
    "è‡ºä¸­\n",
    "åœ°è‡º\n",
    "æœˆè‡º\n",
    "æ«ƒè‡º\n",
    "... (åŒ…å«æ›´å¤š 'è‡º' å­—çš„è©å½™)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 2: ä½¿ç”¨ EasyOCR Trainer è¨“ç·´æ¨¡å‹\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Clone EasyOCR repository:\n",
    "   git clone https://github.com/JaidedAI/EasyOCR.git\n",
    "   cd EasyOCR/trainer\n",
    "\n",
    "2. å®‰è£ä¾è³´:\n",
    "   pip install -r requirements.txt\n",
    "\n",
    "3. æº–å‚™è³‡æ–™é›†æ ¼å¼:\n",
    "   training_data/\n",
    "   â”œâ”€â”€ gt.txt  (æ¨™è¨»æª”æ¡ˆ)\n",
    "   â””â”€â”€ images/\n",
    "       â”œâ”€â”€ img_1.jpg\n",
    "       â”œâ”€â”€ img_2.jpg\n",
    "       â””â”€â”€ ...\n",
    "\n",
    "   gt.txt æ ¼å¼:\n",
    "   images/img_1.jpg\tå¹³è‡º\n",
    "   images/img_2.jpg\tè‡ºç£\n",
    "   images/img_3.jpg\tç¾æ™¯èŠ±åœ’å¹³è‡º72è™Ÿèˆ–\n",
    "\n",
    "4. ä¿®æ”¹é…ç½®æª”æ¡ˆ (config.yaml):\n",
    "   train_data: ./training_data\n",
    "   valid_data: ./validation_data\n",
    "   select_data: ['/']\n",
    "   batch_ratio: ['1.0']\n",
    "   batch_size: 32\n",
    "   num_iter: 10000\n",
    "   valInterval: 500\n",
    "   saved_model: ./saved_models\n",
    "   character: 'ä½ çš„å­—ç¬¦é›†(åŒ…å«è‡ºå­—)'\n",
    "   \n",
    "5. é–‹å§‹è¨“ç·´:\n",
    "   python train.py --config config.yaml\n",
    "\n",
    "6. è¨“ç·´å®Œæˆå¾Œæœƒå¾—åˆ°:\n",
    "   saved_models/best_accuracy.pth\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 3: æº–å‚™ä¸‰å€‹å¿…è¦æª”æ¡ˆ\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "ä½ éœ€è¦æº–å‚™ä¸‰å€‹æª”æ¡ˆ (ç¯„ä¾‹åœ¨ custom_example.zip):\n",
    "\n",
    "1. taiwan_custom.pth (è¨“ç·´å¥½çš„æ¨¡å‹)\n",
    "2. taiwan_custom.yaml (é…ç½®æª”æ¡ˆ)\n",
    "   å…§å®¹:\n",
    "   ---\n",
    "   network_params:\n",
    "     input_channel: 1\n",
    "     output_channel: 512\n",
    "     hidden_size: 256\n",
    "   character: 'ä½ çš„å­—ç¬¦é›†'\n",
    "\n",
    "3. taiwan_custom.py (ç¶²è·¯å®šç¾©)\n",
    "   å…§å®¹:\n",
    "   from easyocr.model.vgg_model import Model\n",
    "   # ä½¿ç”¨é è¨­çš„ VGG-BiLSTM-CTC æ¶æ§‹\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 4: å®‰è£ä¸¦ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. å°‡æª”æ¡ˆæ”¾åˆ°æŒ‡å®šä½ç½®:\n",
    "   cp taiwan_custom.py ~/.EasyOCR/user_network/\n",
    "   cp taiwan_custom.yaml ~/.EasyOCR/user_network/\n",
    "   cp taiwan_custom.pth ~/.EasyOCR/model/\n",
    "\n",
    "2. ä½¿ç”¨è‡ªè¨‚æ¨¡å‹:\n",
    "   import easyocr\n",
    "   reader = easyocr.Reader(\n",
    "       ['ch_tra', 'en'], \n",
    "       recog_network='taiwan_custom',  # ä½¿ç”¨ä½ çš„æ¨¡å‹\n",
    "       gpu=True\n",
    "   )\n",
    "   \n",
    "   results = reader.readtext('./samples/2.jpeg')\n",
    "   for bbox, text, conf in results:\n",
    "       print(f\"[{conf:.2f}] {text}\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âš ï¸ é‡è¦æé†’\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. è¨“ç·´ Recognition Model éœ€è¦:\n",
    "   - GPU (è‡³å°‘ RTX 2060 ä»¥ä¸Š)\n",
    "   - å¤§é‡åŒ…å« 'è‡º' å­—çš„è¨“ç·´è³‡æ–™ (å»ºè­° 500-1000 å¼µ)\n",
    "   - è¨“ç·´æ™‚é–“: æ•¸å°æ™‚åˆ° 1-2 å¤©\n",
    "\n",
    "2. ä¸éœ€è¦è¨“ç·´ CRAFT (æ–‡å­—æª¢æ¸¬æ¨¡å‹):\n",
    "   - craft/README.md æ˜¯ç”¨ä¾†è¨“ç·´æ–‡å­—ä½ç½®æª¢æ¸¬\n",
    "   - ä½ çš„å•é¡Œæ˜¯å­—ç¬¦è¾¨è­˜,ä¸æ˜¯æ–‡å­—æª¢æ¸¬\n",
    "   - æ‰€ä»¥ä¸éœ€è¦ä½¿ç”¨ craft/README.md çš„å…§å®¹\n",
    "\n",
    "3. å»ºè­°å„ªå…ˆä½¿ç”¨ æ–¹æ¡ˆ 1 (å¾Œè™•ç†):\n",
    "   - æˆæœ¬: é›¶\n",
    "   - æ™‚é–“: ç«‹å³å¯ç”¨\n",
    "   - æ•ˆæœ: å¯è§£æ±º 90% çš„ 'è‡º' å­—éŒ¯èª¤\n",
    "\"\"\")\n",
    "\n",
    "# å¯¦ç”¨çš„å­—ç¬¦é›†ç”Ÿæˆå™¨\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å­—ç¬¦é›†æº–å‚™å·¥å…·\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "\n",
    "def generate_character_set(data_folder):\n",
    "    \"\"\"\n",
    "    å¾è¨“ç·´è³‡æ–™ä¸­è‡ªå‹•ç”Ÿæˆå­—ç¬¦é›†\n",
    "    \"\"\"\n",
    "    chars = set()\n",
    "    \n",
    "    gt_file = os.path.join(data_folder, 'gt.txt')\n",
    "    if os.path.exists(gt_file):\n",
    "        with open(gt_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    text = parts[1]\n",
    "                    chars.update(text)\n",
    "    \n",
    "    # ç¢ºä¿åŒ…å« 'è‡º' å­—\n",
    "    chars.add('è‡º')\n",
    "    \n",
    "    # æ’åºä¸¦è¿”å›\n",
    "    char_list = sorted(list(chars))\n",
    "    return ''.join(char_list)\n",
    "\n",
    "print(\"\"\"\n",
    "ä½¿ç”¨æ–¹å¼:\n",
    "charset = generate_character_set('./training_data')\n",
    "print(f\"å­—ç¬¦é›†: {charset}\")\n",
    "\n",
    "ç„¶å¾Œå°‡é€™å€‹å­—ç¬¦é›†æ”¾å…¥ config.yaml çš„ 'character' æ¬„ä½\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916bcd0",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š å…©å€‹ MD æ–‡ä»¶çš„ç¸½çµå°æ¯”\n",
    "\n",
    "| æ–‡ä»¶ | ç”¨é€” | æ˜¯å¦éœ€è¦ | èªªæ˜ |\n",
    "|------|------|----------|------|\n",
    "| **custom_model.md** | è¨“ç·´ **Recognition Model**<br>(å­—ç¬¦è¾¨è­˜) | âœ… **éœ€è¦** | è§£æ±º \"è‡ºâ†’å£¼\" çš„å•é¡Œ<br>è¨“ç·´å­—ç¬¦è¾¨è­˜æ¨¡å‹ |\n",
    "| **craft/README.md** | è¨“ç·´ **CRAFT**<br>(æ–‡å­—æª¢æ¸¬) | âŒ **ä¸éœ€è¦** | ç”¨æ–¼æ‰¾æ–‡å­—ä½ç½®<br>ä½ çš„æª¢æ¸¬å·²æ­£å¸¸ |\n",
    "\n",
    "### ğŸ¯ é‡å°æ‚¨çš„å•é¡Œå»ºè­°:\n",
    "\n",
    "#### çŸ­æœŸè§£æ±ºæ–¹æ¡ˆ (ç«‹å³å¯ç”¨):\n",
    "1. âœ… **ä½¿ç”¨æ–¹æ¡ˆ 1 çš„å¾Œè™•ç†ä¿®æ­£** (5åˆ†é˜å®Œæˆ)\n",
    "   - ç›´æ¥æ›¿æ› `å£¼ â†’ è‡º`ã€`è€‹è‡º â†’ è‡º`\n",
    "   - æˆæœ¬: é›¶\n",
    "   - æ•ˆæœ: 95%+ æº–ç¢ºç‡\n",
    "\n",
    "#### é•·æœŸè§£æ±ºæ–¹æ¡ˆ (å¦‚æœè¦å®Œç¾):\n",
    "2. âš ï¸ **è¨“ç·´è‡ªè¨‚ Recognition Model** (1-2é€±)\n",
    "   - æŒ‰ç…§ `custom_model.md` çš„æ­¥é©Ÿ\n",
    "   - ä½¿ç”¨ deep-text-recognition-benchmark æˆ– EasyOCR/trainer\n",
    "   - éœ€è¦ GPU å’Œè¨“ç·´è³‡æ–™\n",
    "   - æˆæœ¬: $200-500 (GPUç§Ÿç”¨)\n",
    "   - æ•ˆæœ: 99%+ æº–ç¢ºç‡\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ å¯¦å‹™å»ºè­°:\n",
    "\n",
    "**å…ˆç”¨æ–¹æ¡ˆ 1 (å¾Œè™•ç†)**, å› ç‚º:\n",
    "- å°ç£åœ°å€ä¸­ \"è‡º\" å­—éŒ¯èª¤æ˜¯å¯é æ¸¬çš„æ¨¡å¼\n",
    "- é€šå¸¸å‡ºç¾åœ¨: å¹³è‡ºã€è‡ºåŒ—ã€è‡ºç£ã€è‡ºä¸­ç­‰å›ºå®šè©å½™\n",
    "- å¯ä»¥å»ºç«‹å®Œæ•´çš„éŒ¯èª¤å°ç…§è¡¨\n",
    "- ç„¡éœ€è¨“ç·´,ç«‹å³è¦‹æ•ˆ\n",
    "\n",
    "**åªæœ‰åœ¨ä»¥ä¸‹æƒ…æ³æ‰éœ€è¦è¨“ç·´æ¨¡å‹**:\n",
    "- å¾Œè™•ç†ç„¡æ³•è¦†è“‹æ‰€æœ‰éŒ¯èª¤æƒ…æ³\n",
    "- æœ‰å¤§é‡ä¸åŒçš„ \"è‡º\" å­—ä½¿ç”¨å ´æ™¯\n",
    "- é ç®—å’Œæ™‚é–“å……è¶³\n",
    "- æœ‰ GPU è³‡æºå¯ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7559f3f",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“š å®Œæ•´è¨“ç·´æº–å‚™æµç¨‹ (æ ¹æ“š custom_model.md)\n",
    "\n",
    "## éšæ®µ 1ï¸âƒ£: ç’°å¢ƒæº–å‚™èˆ‡å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 1: æª¢æŸ¥ç’°å¢ƒèˆ‡å®‰è£å¿…è¦å¥—ä»¶\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 1.1: æª¢æŸ¥ Python ç’°å¢ƒ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"Python è·¯å¾‘: {sys.executable}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 1.2: æª¢æŸ¥ GPU å¯ç”¨æ€§\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "    print(f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        print(f\"GPU åç¨±: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU æ•¸é‡: {torch.cuda.device_count()}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ è­¦å‘Š: ç„¡ GPU å¯ç”¨,è¨“ç·´æœƒéå¸¸æ…¢!\")\n",
    "        print(\"å»ºè­°: ä½¿ç”¨ Google Colab æˆ–é›²ç«¯ GPU æœå‹™\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorch æœªå®‰è£\")\n",
    "    print(\"è«‹åŸ·è¡Œ: pip install torch torchvision\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 1.3: å®‰è£è¨“ç·´æ‰€éœ€å¥—ä»¶\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å¿…è¦å¥—ä»¶æ¸…å–®\n",
    "required_packages = {\n",
    "    'torch': 'PyTorch (æ·±åº¦å­¸ç¿’æ¡†æ¶)',\n",
    "    'torchvision': 'PyTorch è¦–è¦ºå¥—ä»¶',\n",
    "    'Pillow': 'åœ–ç‰‡è™•ç†',\n",
    "    'lmdb': 'è³‡æ–™åº« (è¨“ç·´è³‡æ–™å„²å­˜)',\n",
    "    'trdg': 'TextRecognitionDataGenerator (ç”Ÿæˆè¨“ç·´è³‡æ–™)',\n",
    "}\n",
    "\n",
    "print(\"æª¢æŸ¥å·²å®‰è£çš„å¥—ä»¶:\")\n",
    "for package, description in required_packages.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package:20s} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package:20s} - {description} (æœªå®‰è£)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å®‰è£æŒ‡ä»¤ (å¦‚æœ‰å¥—ä»¶æœªå®‰è£,è«‹åŸ·è¡Œ):\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "# åŸºç¤å¥—ä»¶\n",
    "pip install torch torchvision Pillow lmdb six\n",
    "\n",
    "# è³‡æ–™ç”Ÿæˆå·¥å…·\n",
    "pip install trdg\n",
    "\n",
    "# EasyOCR (å¦‚å°šæœªå®‰è£)\n",
    "pip install easyocr\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372aa6ec",
   "metadata": {},
   "source": [
    "---\n",
    "## éšæ®µ 2ï¸âƒ£: Clone è¨“ç·´ç¨‹å¼ç¢¼\n",
    "\n",
    "æ ¹æ“š custom_model.md,æˆ‘å€‘éœ€è¦ä½¿ç”¨ **deep-text-recognition-benchmark** æˆ– **EasyOCR/trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 2: Clone è¨“ç·´ç¨‹å¼ç¢¼\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 2.1: é¸æ“‡è¨“ç·´å·¥å…·\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "æ ¹æ“š custom_model.md,æœ‰å…©å€‹é¸æ“‡:\n",
    "\n",
    "é¸é … A: deep-text-recognition-benchmark (å®˜æ–¹æ¨è–¦)\n",
    "  - GitHub: https://github.com/clovaai/deep-text-recognition-benchmark\n",
    "  - å„ªé»: æ–‡æª”å®Œæ•´,ç¤¾ç¾¤æ”¯æ´å¥½\n",
    "  - é©åˆ: åˆå­¸è€…\n",
    "\n",
    "é¸é … B: EasyOCR/trainer (EasyOCR å®˜æ–¹)\n",
    "  - GitHub: https://github.com/JaidedAI/EasyOCR/tree/master/trainer\n",
    "  - å„ªé»: èˆ‡ EasyOCR æ•´åˆåº¦é«˜\n",
    "  - é©åˆ: é€²éšä½¿ç”¨è€…\n",
    "\n",
    "æˆ‘å€‘ä½¿ç”¨ é¸é … A (deep-text-recognition-benchmark)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 2.2: Clone Repository\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è¨­å®šå·¥ä½œç›®éŒ„\n",
    "workspace_dir = os.path.expanduser(\"~/easyocr_training\")\n",
    "repo_dir = os.path.join(workspace_dir, \"deep-text-recognition-benchmark\")\n",
    "\n",
    "print(f\"å·¥ä½œç›®éŒ„: {workspace_dir}\")\n",
    "print(f\"Repository å°‡ clone åˆ°: {repo_dir}\")\n",
    "\n",
    "# å»ºç«‹æŒ‡ä»¤\n",
    "clone_commands = f\"\"\"\n",
    "# å»ºç«‹å·¥ä½œç›®éŒ„\n",
    "mkdir -p {workspace_dir}\n",
    "cd {workspace_dir}\n",
    "\n",
    "# Clone deep-text-recognition-benchmark\n",
    "git clone https://github.com/clovaai/deep-text-recognition-benchmark.git\n",
    "cd deep-text-recognition-benchmark\n",
    "\n",
    "# å®‰è£ä¾è³´\n",
    "pip install -r requirements.txt\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nè«‹åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤:\")\n",
    "print(clone_commands)\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦å·²ç¶“ clone\n",
    "if os.path.exists(repo_dir):\n",
    "    print(f\"\\nâœ… Repository å·²å­˜åœ¨æ–¼: {repo_dir}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Repository å°šæœª clone\")\n",
    "    print(f\"è«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä¸Šè¿°æŒ‡ä»¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13255f10",
   "metadata": {},
   "source": [
    "---\n",
    "## éšæ®µ 3ï¸âƒ£: æº–å‚™è¨“ç·´è³‡æ–™\n",
    "\n",
    "é€™æ˜¯æœ€é‡è¦çš„æ­¥é©Ÿ!éœ€è¦ç”ŸæˆåŒ…å« \"è‡º\" å­—çš„è¨“ç·´è³‡æ–™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7361ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 3: æº–å‚™è¨“ç·´è³‡æ–™ - å»ºç«‹åŒ…å« \"è‡º\" å­—çš„è©å½™è¡¨\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 3.1: å»ºç«‹å°ç£åœ°å€å¸¸ç”¨è©å½™è¡¨\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åŒ…å« \"è‡º\" å­—çš„å¸¸ç”¨è©å½™\n",
    "taiwan_vocabulary = [\n",
    "    # å¹³è‡ºç›¸é—œ\n",
    "    \"å¹³è‡º\", \"åœ°è‡º\", \"æœˆè‡º\", \"æ«ƒè‡º\", \"é™½è‡º\", \"èˆè‡º\", \"è¬›è‡º\", \"è‡ºéš\",\n",
    "    \n",
    "    # å°ç£åœ°å\n",
    "    \"è‡ºç£\", \"è‡ºåŒ—\", \"è‡ºä¸­\", \"è‡ºå—\", \"è‡ºæ±\", \n",
    "    \"æ–°åŒ—å¸‚\", \"è‡ºåŒ—å¸‚\", \"è‡ºä¸­å¸‚\", \"è‡ºå—å¸‚\",\n",
    "    \n",
    "    # å¸¸è¦‹åœ°å€ç”¨èª\n",
    "    \"ä¸€æ¨“å¹³è‡º\", \"äºŒæ¨“å¹³è‡º\", \"ä¸‰æ¨“å¹³è‡º\", \"åœ°ä¸‹å¹³è‡º\",\n",
    "    \"ç¾æ™¯èŠ±åœ’å¹³è‡º\", \"é™½å…‰å¤§å»ˆå¹³è‡º\", \"å¹¸ç¦ç¤¾å€å¹³è‡º\",\n",
    "    \n",
    "    # å®Œæ•´åœ°å€ç¯„ä¾‹\n",
    "    \"ä¹é¾é’è¡£ç´°å±±è·¯2è™Ÿç¾æ™¯èŠ±åœ’å¹³è‡º72è™Ÿèˆ–\",\n",
    "    \"ä¹é¾é’è¡£ç´°å±±è·¯ç¾æ™¯èŠ±åœ’å¹³è‡º\",\n",
    "    \"ç¾æ™¯èŠ±åœ’å¹³è‡º72è™Ÿ\",\n",
    "    \"å¹³è‡º72è™Ÿèˆ–\",\n",
    "    \n",
    "    # å…¶ä»–å¸¸è¦‹ç”¨æ³•\n",
    "    \"è‡ºå¹£\", \"è‡ºé›»\", \"è‡ºéµ\", \"è‡ºç³–\",\n",
    "    \"å‰è‡º\", \"å¾Œè‡º\", \"æŸœè‡º\", \"è‡ºé¢\",\n",
    "    \n",
    "    # æ•¸å­—çµ„åˆ\n",
    "    \"å¹³è‡º1è™Ÿ\", \"å¹³è‡º2è™Ÿ\", \"å¹³è‡º3è™Ÿ\", \"å¹³è‡º10è™Ÿ\",\n",
    "    \"å¹³è‡º20è™Ÿ\", \"å¹³è‡º30è™Ÿ\", \"å¹³è‡º50è™Ÿ\", \"å¹³è‡º100è™Ÿ\",\n",
    "]\n",
    "\n",
    "# å»ºç«‹è³‡æ–™é›†ç›®éŒ„\n",
    "data_dir = os.path.expanduser(\"~/easyocr_training/training_data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# å„²å­˜è©å½™è¡¨\n",
    "vocab_file = os.path.join(data_dir, \"taiwan_vocab.txt\")\n",
    "with open(vocab_file, 'w', encoding='utf-8') as f:\n",
    "    for word in taiwan_vocabulary:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "print(f\"âœ… å·²å»ºç«‹è©å½™è¡¨: {vocab_file}\")\n",
    "print(f\"ğŸ“Š ç¸½å…± {len(taiwan_vocabulary)} å€‹è©å½™\")\n",
    "print(f\"\\nå‰ 20 å€‹è©å½™:\")\n",
    "for i, word in enumerate(taiwan_vocabulary[:20], 1):\n",
    "    print(f\"  {i:2d}. {word}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 3.2: æº–å‚™å­—ç¬¦é›† (Character Set)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰å­—ç¬¦\n",
    "all_chars = set()\n",
    "for word in taiwan_vocabulary:\n",
    "    all_chars.update(word)\n",
    "\n",
    "# åŠ å…¥æ•¸å­—å’Œæ¨™é»ç¬¦è™Ÿ\n",
    "all_chars.update('0123456789')\n",
    "all_chars.update('è™Ÿèˆ–æ¨“å®¤åº§æ£Ÿå··å¼„è·¯è¡—æ®µå€å¸‚ç¸£é„‰é®æ‘é‡Œé„°')\n",
    "\n",
    "# æ’åº\n",
    "char_list = sorted(list(all_chars))\n",
    "charset = ''.join(char_list)\n",
    "\n",
    "print(f\"å­—ç¬¦é›†å¤§å°: {len(char_list)} å€‹å­—ç¬¦\")\n",
    "print(f\"å­—ç¬¦é›†: {charset}\")\n",
    "\n",
    "# å„²å­˜å­—ç¬¦é›†\n",
    "charset_file = os.path.join(data_dir, \"character_set.txt\")\n",
    "with open(charset_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(charset)\n",
    "\n",
    "print(f\"\\nâœ… å·²å„²å­˜å­—ç¬¦é›†: {charset_file}\")\n",
    "\n",
    "# æª¢æŸ¥ 'è‡º' å­—æ˜¯å¦åœ¨å­—ç¬¦é›†ä¸­\n",
    "if 'è‡º' in char_list:\n",
    "    print(\"âœ… 'è‡º' å­—å·²åŒ…å«åœ¨å­—ç¬¦é›†ä¸­\")\n",
    "else:\n",
    "    print(\"âŒ éŒ¯èª¤: 'è‡º' å­—ä¸åœ¨å­—ç¬¦é›†ä¸­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 3.3: ä½¿ç”¨ TextRecognitionDataGenerator ç”Ÿæˆè¨“ç·´åœ–ç‰‡\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 3.3: ç”Ÿæˆè¨“ç·´åœ–ç‰‡\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "data_dir = os.path.expanduser(\"~/easyocr_training/training_data\")\n",
    "vocab_file = os.path.join(data_dir, \"taiwan_vocab.txt\")\n",
    "output_dir = os.path.join(data_dir, \"generated_images\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"è©å½™è¡¨: {vocab_file}\")\n",
    "print(f\"è¼¸å‡ºç›®éŒ„: {output_dir}\")\n",
    "\n",
    "# ç”ŸæˆæŒ‡ä»¤\n",
    "trdg_command = f\"\"\"\n",
    "# ä½¿ç”¨ trdg ç”Ÿæˆè¨“ç·´åœ–ç‰‡\n",
    "trdg -c 2000 \\\\\n",
    "     -w 1 \\\\\n",
    "     -f 64 \\\\\n",
    "     -t 4 \\\\\n",
    "     -k 5 \\\\\n",
    "     -rk \\\\\n",
    "     -bl 2 \\\\\n",
    "     -rbl \\\\\n",
    "     -na 2 \\\\\n",
    "     -tc '#000000,#333333,#666666' \\\\\n",
    "     -d 3 \\\\\n",
    "     -do \\\\\n",
    "     -k 5 \\\\\n",
    "     -i {vocab_file} \\\\\n",
    "     -o {output_dir}\n",
    "\n",
    "åƒæ•¸èªªæ˜:\n",
    "-c 2000      : ç”Ÿæˆ 2000 å¼µåœ–ç‰‡\n",
    "-w 1         : æ¯å¼µåœ–ç‰‡ 1 å€‹è©\n",
    "-f 64        : å­—é«”å¤§å° 64\n",
    "-t 4         : ä½¿ç”¨ 4 å€‹åŸ·è¡Œç·’\n",
    "-k 5         : å‚¾æ–œè§’åº¦ Â±5 åº¦\n",
    "-rk          : éš¨æ©Ÿå‚¾æ–œ\n",
    "-bl 2        : æ¨¡ç³Šç¨‹åº¦ 2\n",
    "-rbl         : éš¨æ©Ÿæ¨¡ç³Š\n",
    "-na 2        : æ·»åŠ å™ªé»\n",
    "-tc '#...'   : æ–‡å­—é¡è‰² (é»‘ã€æ·±ç°ã€ç°)\n",
    "-d 3         : æ‰­æ›²ç¨‹åº¦\n",
    "-do          : å•Ÿç”¨æ‰­æ›²\n",
    "-i           : è¼¸å…¥è©å½™è¡¨\n",
    "-o           : è¼¸å‡ºç›®éŒ„\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nè«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤:\")\n",
    "print(trdg_command)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æˆ–ä½¿ç”¨ Python ç›´æ¥åŸ·è¡Œ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ä½¿ç”¨ Python API ç”Ÿæˆ (éœ€è¦å®‰è£ trdg)\n",
    "try:\n",
    "    from trdg.generators import GeneratorFromStrings\n",
    "    \n",
    "    print(\"æ­£åœ¨ä½¿ç”¨ trdg ç”Ÿæˆåœ–ç‰‡...\")\n",
    "    \n",
    "    # è®€å–è©å½™\n",
    "    with open(vocab_file, 'r', encoding='utf-8') as f:\n",
    "        strings = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    # ç”Ÿæˆå™¨è¨­å®š\n",
    "    generator = GeneratorFromStrings(\n",
    "        strings=strings,\n",
    "        count=min(len(strings) * 3, 2000),  # æ¯å€‹è©ç”Ÿæˆ 3 å¼µ,æœ€å¤š 2000 å¼µ\n",
    "        fonts=['STHeiti', 'Arial Unicode MS'],  # Mac ä¸­æ–‡å­—é«”\n",
    "        size=64,\n",
    "        skewing_angle=5,\n",
    "        random_skew=True,\n",
    "        blur=2,\n",
    "        random_blur=True,\n",
    "        background_type=0,  # ç´”è‰²èƒŒæ™¯\n",
    "        distorsion_type=2,  # æ‰­æ›²é¡å‹\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆåœ–ç‰‡\n",
    "    count = 0\n",
    "    for img, lbl in generator:\n",
    "        img_path = os.path.join(output_dir, f\"img_{count:05d}.jpg\")\n",
    "        lbl_path = os.path.join(output_dir, f\"img_{count:05d}.txt\")\n",
    "        \n",
    "        # å„²å­˜åœ–ç‰‡\n",
    "        img.save(img_path)\n",
    "        \n",
    "        # å„²å­˜æ¨™ç±¤\n",
    "        with open(lbl_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(lbl)\n",
    "        \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"å·²ç”Ÿæˆ {count} å¼µåœ–ç‰‡...\")\n",
    "        \n",
    "        if count >= 2000:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nâœ… æˆåŠŸç”Ÿæˆ {count} å¼µè¨“ç·´åœ–ç‰‡!\")\n",
    "    print(f\"ğŸ“ åœ–ç‰‡ä½ç½®: {output_dir}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ trdg æœªå®‰è£\")\n",
    "    print(\"è«‹åŸ·è¡Œ: pip install trdg\")\n",
    "    print(\"ç„¶å¾Œåœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä¸Šè¿°æŒ‡ä»¤\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ç”Ÿæˆå¤±æ•—: {e}\")\n",
    "    print(\"è«‹æ”¹ç”¨çµ‚ç«¯æ©ŸæŒ‡ä»¤ç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 3.4: è½‰æ›è³‡æ–™æ ¼å¼ç‚º LMDB (deep-text-recognition-benchmark æ ¼å¼)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 3.4: è½‰æ›è³‡æ–™ç‚º LMDB æ ¼å¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "import lmdb\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import six\n",
    "\n",
    "def create_lmdb_dataset(input_dir, output_dir, charset_file):\n",
    "    \"\"\"\n",
    "    å°‡ç”Ÿæˆçš„åœ–ç‰‡è½‰æ›ç‚º LMDB æ ¼å¼\n",
    "    \n",
    "    Args:\n",
    "        input_dir: åŒ…å«åœ–ç‰‡å’Œæ¨™ç±¤çš„ç›®éŒ„\n",
    "        output_dir: LMDB è³‡æ–™åº«è¼¸å‡ºç›®éŒ„\n",
    "        charset_file: å­—ç¬¦é›†æª”æ¡ˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # è®€å–å­—ç¬¦é›†\n",
    "    with open(charset_file, 'r', encoding='utf-8') as f:\n",
    "        charset = f.read().strip()\n",
    "    \n",
    "    print(f\"è¼¸å…¥ç›®éŒ„: {input_dir}\")\n",
    "    print(f\"è¼¸å‡ºç›®éŒ„: {output_dir}\")\n",
    "    print(f\"å­—ç¬¦é›†: {len(charset)} å€‹å­—ç¬¦\")\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡\n",
    "    image_files = []\n",
    "    for fname in sorted(os.listdir(input_dir)):\n",
    "        if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "            txt_file = fname.rsplit('.', 1)[0] + '.txt'\n",
    "            txt_path = os.path.join(input_dir, txt_file)\n",
    "            if os.path.exists(txt_path):\n",
    "                image_files.append(fname)\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(image_files)} å¼µæœ‰æ¨™ç±¤çš„åœ–ç‰‡\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"âŒ éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°ä»»ä½•åœ–ç‰‡!\")\n",
    "        return\n",
    "    \n",
    "    # å»ºç«‹ LMDB è³‡æ–™åº«\n",
    "    env = lmdb.open(output_dir, map_size=1099511627776)  # 1TB\n",
    "    \n",
    "    with env.begin(write=True) as txn:\n",
    "        cnt = 0\n",
    "        for img_fname in image_files:\n",
    "            # è®€å–åœ–ç‰‡\n",
    "            img_path = os.path.join(input_dir, img_fname)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # è½‰ç‚º bytes\n",
    "            img_byte_arr = np.array(img)\n",
    "            _, img_encoded = cv2.imencode('.jpg', img_byte_arr)\n",
    "            img_bytes = img_encoded.tobytes()\n",
    "            \n",
    "            # è®€å–æ¨™ç±¤\n",
    "            txt_fname = img_fname.rsplit('.', 1)[0] + '.txt'\n",
    "            txt_path = os.path.join(input_dir, txt_fname)\n",
    "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                label = f.read().strip()\n",
    "            \n",
    "            # å¯«å…¥ LMDB\n",
    "            imageKey = f'image-{cnt+1:09d}'.encode()\n",
    "            labelKey = f'label-{cnt+1:09d}'.encode()\n",
    "            \n",
    "            txn.put(imageKey, img_bytes)\n",
    "            txn.put(labelKey, label.encode('utf-8'))\n",
    "            \n",
    "            cnt += 1\n",
    "            if cnt % 100 == 0:\n",
    "                print(f\"å·²è™•ç† {cnt}/{len(image_files)} å¼µåœ–ç‰‡...\")\n",
    "        \n",
    "        # å¯«å…¥çµ±è¨ˆè³‡è¨Š\n",
    "        txn.put('num-samples'.encode(), str(cnt).encode())\n",
    "    \n",
    "    env.close()\n",
    "    print(f\"\\nâœ… LMDB è³‡æ–™åº«å»ºç«‹å®Œæˆ!\")\n",
    "    print(f\"   ç¸½å…± {cnt} å¼µåœ–ç‰‡\")\n",
    "    print(f\"   ä½ç½®: {output_dir}\")\n",
    "    \n",
    "    return cnt\n",
    "\n",
    "# åŸ·è¡Œè½‰æ›\n",
    "data_dir = os.path.expanduser(\"~/easyocr_training/training_data\")\n",
    "input_dir = os.path.join(data_dir, \"generated_images\")\n",
    "train_lmdb = os.path.join(data_dir, \"train_lmdb\")\n",
    "val_lmdb = os.path.join(data_dir, \"val_lmdb\")\n",
    "charset_file = os.path.join(data_dir, \"character_set.txt\")\n",
    "\n",
    "if os.path.exists(input_dir) and os.listdir(input_dir):\n",
    "    try:\n",
    "        # ç”Ÿæˆè¨“ç·´é›† (80%) å’Œé©—è­‰é›† (20%)\n",
    "        all_files = [f for f in os.listdir(input_dir) if f.endswith('.jpg')]\n",
    "        n_total = len(all_files)\n",
    "        n_train = int(n_total * 0.8)\n",
    "        \n",
    "        print(f\"\\nç¸½åœ–ç‰‡æ•¸: {n_total}\")\n",
    "        print(f\"è¨“ç·´é›†: {n_train} å¼µ (80%)\")\n",
    "        print(f\"é©—è­‰é›†: {n_total - n_train} å¼µ (20%)\")\n",
    "        \n",
    "        # åˆ†å‰²æª”æ¡ˆ\n",
    "        import random\n",
    "        random.shuffle(all_files)\n",
    "        train_files = all_files[:n_train]\n",
    "        val_files = all_files[n_train:]\n",
    "        \n",
    "        # å»ºç«‹è‡¨æ™‚ç›®éŒ„\n",
    "        train_tmp = os.path.join(data_dir, \"train_tmp\")\n",
    "        val_tmp = os.path.join(data_dir, \"val_tmp\")\n",
    "        os.makedirs(train_tmp, exist_ok=True)\n",
    "        os.makedirs(val_tmp, exist_ok=True)\n",
    "        \n",
    "        # è¤‡è£½æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„\n",
    "        import shutil\n",
    "        print(\"\\nè¤‡è£½è¨“ç·´é›†æª”æ¡ˆ...\")\n",
    "        for f in train_files:\n",
    "            shutil.copy(os.path.join(input_dir, f), train_tmp)\n",
    "            txt_f = f.rsplit('.', 1)[0] + '.txt'\n",
    "            if os.path.exists(os.path.join(input_dir, txt_f)):\n",
    "                shutil.copy(os.path.join(input_dir, txt_f), train_tmp)\n",
    "        \n",
    "        print(\"è¤‡è£½é©—è­‰é›†æª”æ¡ˆ...\")\n",
    "        for f in val_files:\n",
    "            shutil.copy(os.path.join(input_dir, f), val_tmp)\n",
    "            txt_f = f.rsplit('.', 1)[0] + '.txt'\n",
    "            if os.path.exists(os.path.join(input_dir, txt_f)):\n",
    "                shutil.copy(os.path.join(input_dir, txt_f), val_tmp)\n",
    "        \n",
    "        # å»ºç«‹ LMDB\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"å»ºç«‹è¨“ç·´é›† LMDB\")\n",
    "        print(\"=\"*60)\n",
    "        create_lmdb_dataset(train_tmp, train_lmdb, charset_file)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"å»ºç«‹é©—è­‰é›† LMDB\")\n",
    "        print(\"=\"*60)\n",
    "        create_lmdb_dataset(val_tmp, val_lmdb, charset_file)\n",
    "        \n",
    "        # æ¸…ç†è‡¨æ™‚ç›®éŒ„\n",
    "        shutil.rmtree(train_tmp)\n",
    "        shutil.rmtree(val_tmp)\n",
    "        \n",
    "        print(\"\\nâœ… è³‡æ–™æº–å‚™å®Œæˆ!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ éŒ¯èª¤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f\"âš ï¸ è«‹å…ˆåŸ·è¡Œä¸Šä¸€å€‹ cell ç”Ÿæˆåœ–ç‰‡\")\n",
    "    print(f\"   æˆ–ç¢ºèªç›®éŒ„å­˜åœ¨: {input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5037a6",
   "metadata": {},
   "source": [
    "---\n",
    "## éšæ®µ 4ï¸âƒ£: é…ç½®è¨“ç·´åƒæ•¸\n",
    "\n",
    "æ ¹æ“š custom_model.md,ç¶²è·¯æ¶æ§‹å¿…é ˆæ˜¯ **None-VGG-BiLSTM-CTC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 4: å»ºç«‹è¨“ç·´é…ç½®\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 4.1: ç”Ÿæˆè¨“ç·´æŒ‡ä»¤\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è·¯å¾‘è¨­å®š\n",
    "data_dir = os.path.expanduser(\"~/easyocr_training/training_data\")\n",
    "train_lmdb = os.path.join(data_dir, \"train_lmdb\")\n",
    "val_lmdb = os.path.join(data_dir, \"val_lmdb\")\n",
    "charset_file = os.path.join(data_dir, \"character_set.txt\")\n",
    "repo_dir = os.path.expanduser(\"~/easyocr_training/deep-text-recognition-benchmark\")\n",
    "saved_models = os.path.join(data_dir, \"saved_models\")\n",
    "\n",
    "# è®€å–å­—ç¬¦é›†\n",
    "try:\n",
    "    with open(charset_file, 'r', encoding='utf-8') as f:\n",
    "        charset = f.read().strip()\n",
    "    print(f\"âœ… å­—ç¬¦é›†è¼‰å…¥æˆåŠŸ: {len(charset)} å€‹å­—ç¬¦\")\n",
    "except:\n",
    "    print(f\"âŒ ç„¡æ³•è¼‰å…¥å­—ç¬¦é›†: {charset_file}\")\n",
    "    charset = \"\"\n",
    "\n",
    "# æ ¹æ“š custom_model.md,å¿…é ˆä½¿ç”¨ None-VGG-BiLSTM-CTC\n",
    "training_command = f\"\"\"\n",
    "cd {repo_dir}\n",
    "\n",
    "# è¨“ç·´æŒ‡ä»¤ (æ ¹æ“š custom_model.md)\n",
    "python train.py \\\\\n",
    "    --train_data {train_lmdb} \\\\\n",
    "    --valid_data {val_lmdb} \\\\\n",
    "    --select_data / \\\\\n",
    "    --batch_ratio 1.0 \\\\\n",
    "    --Transformation None \\\\\n",
    "    --FeatureExtraction VGG \\\\\n",
    "    --SequenceModeling BiLSTM \\\\\n",
    "    --Prediction CTC \\\\\n",
    "    --batch_size 32 \\\\\n",
    "    --num_iter 10000 \\\\\n",
    "    --valInterval 500 \\\\\n",
    "    --saved_model {saved_models} \\\\\n",
    "    --character '{charset}' \\\\\n",
    "    --manualSeed 1111 \\\\\n",
    "    --workers 4 \\\\\n",
    "    --lr 1.0 \\\\\n",
    "    --adam\n",
    "\n",
    "åƒæ•¸èªªæ˜:\n",
    "--Transformation None    : ä¸ä½¿ç”¨è½‰æ› (å¿…é ˆ!)\n",
    "--FeatureExtraction VGG  : ä½¿ç”¨ VGG ç‰¹å¾µæå– (å¿…é ˆ!)\n",
    "--SequenceModeling BiLSTM: ä½¿ç”¨ BiLSTM åºåˆ—å»ºæ¨¡ (å¿…é ˆ!)\n",
    "--Prediction CTC         : ä½¿ç”¨ CTC é æ¸¬ (å¿…é ˆ!)\n",
    "--batch_size 32          : æ‰¹æ¬¡å¤§å° (æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´)\n",
    "--num_iter 10000         : è¨“ç·´è¿­ä»£æ¬¡æ•¸\n",
    "--valInterval 500        : æ¯ 500 æ¬¡é©—è­‰ä¸€æ¬¡\n",
    "--character              : å­—ç¬¦é›† (åŒ…å« 'è‡º' å­—)\n",
    "--lr 1.0                 : å­¸ç¿’ç‡\n",
    "--adam                   : ä½¿ç”¨ Adam å„ªåŒ–å™¨\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nè«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä»¥ä¸‹è¨“ç·´æŒ‡ä»¤:\")\n",
    "print(training_command)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 4.2: GPU è¨˜æ†¶é«”ä¸è¶³æ™‚çš„èª¿æ•´\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "å¦‚æœè¨“ç·´æ™‚å‡ºç¾ CUDA out of memory éŒ¯èª¤:\n",
    "\n",
    "1. é™ä½ batch_size:\n",
    "   --batch_size 16  (æˆ– 8, 4)\n",
    "\n",
    "2. é™ä½åœ–ç‰‡å¤§å°:\n",
    "   --imgH 32 --imgW 100\n",
    "\n",
    "3. ä½¿ç”¨æ¢¯åº¦ç´¯ç©:\n",
    "   --grad_clip 5\n",
    "\n",
    "4. ä½¿ç”¨ mixed precision training:\n",
    "   --fp16\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ­¥é©Ÿ 4.3: é æœŸè¨“ç·´æ™‚é–“\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "è¨“ç·´æ™‚é–“é ä¼° (10000 iterations):\n",
    "- RTX 4090:  2-3 å°æ™‚\n",
    "- RTX 3090:  4-6 å°æ™‚\n",
    "- RTX 2060:  8-12 å°æ™‚\n",
    "- ç„¡ GPU:    1-2 å¤© (ä¸å»ºè­°)\n",
    "\n",
    "Google Colab (å…è²» GPU):\n",
    "- T4 GPU:    6-8 å°æ™‚\n",
    "- å»ºè­°ä½¿ç”¨ Colab Pro (V100/A100 GPU)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4d671",
   "metadata": {},
   "source": [
    "---\n",
    "## éšæ®µ 5ï¸âƒ£: è¨“ç·´å¾Œçš„æ¨¡å‹æº–å‚™\n",
    "\n",
    "è¨“ç·´å®Œæˆå¾Œ,éœ€è¦æº–å‚™ 3 å€‹æª”æ¡ˆä¾†ä½¿ç”¨è‡ªè¨‚æ¨¡å‹ (æ ¹æ“š custom_model.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 5: æº–å‚™ EasyOCR è‡ªè¨‚æ¨¡å‹æ‰€éœ€çš„ä¸‰å€‹æª”æ¡ˆ\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"è¨“ç·´å®Œæˆå¾Œçš„æ­¥é©Ÿ\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "è¨“ç·´å®Œæˆå¾Œ,æœƒåœ¨ saved_models/ ç›®éŒ„ä¸‹å¾—åˆ°:\n",
    "- best_accuracy.pth (æœ€ä½³æ¨¡å‹æ¬Šé‡)\n",
    "- iter_10000.pth (æœ€çµ‚è¿­ä»£æ¨¡å‹)\n",
    "\n",
    "æ¥ä¸‹ä¾†éœ€è¦æº–å‚™ 3 å€‹æª”æ¡ˆçµ¦ EasyOCR ä½¿ç”¨\n",
    "\"\"\")\n",
    "\n",
    "# æª”æ¡ˆè·¯å¾‘\n",
    "easyocr_user_network = os.path.expanduser(\"~/.EasyOCR/user_network\")\n",
    "easyocr_model_dir = os.path.expanduser(\"~/.EasyOCR/model\")\n",
    "data_dir = os.path.expanduser(\"~/easyocr_training/training_data\")\n",
    "charset_file = os.path.join(data_dir, \"character_set.txt\")\n",
    "\n",
    "os.makedirs(easyocr_user_network, exist_ok=True)\n",
    "os.makedirs(easyocr_model_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æª”æ¡ˆ 1: taiwan_custom.py (ç¶²è·¯å®šç¾©)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å»ºç«‹ç¶²è·¯å®šç¾©æª”æ¡ˆ\n",
    "network_code = '''\"\"\"\n",
    "Taiwan Custom Recognition Model\n",
    "Architecture: None-VGG-BiLSTM-CTC (æ ¹æ“š custom_model.md)\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, hidden_size, num_class):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # VGG Feature Extractor\n",
    "        self.FeatureExtraction = VGG_FeatureExtractor(input_channel, output_channel)\n",
    "        self.FeatureExtraction_output = output_channel\n",
    "        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        \n",
    "        # BiLSTM Sequence Modeling\n",
    "        self.SequenceModeling = nn.Sequential(\n",
    "            BidirectionalLSTM(output_channel, hidden_size, hidden_size),\n",
    "            BidirectionalLSTM(hidden_size, hidden_size, hidden_size)\n",
    "        )\n",
    "        self.SequenceModeling_output = hidden_size\n",
    "        \n",
    "        # CTC Prediction\n",
    "        self.Prediction = nn.Linear(self.SequenceModeling_output, num_class)\n",
    "\n",
    "    def forward(self, input, text):\n",
    "        # Feature extraction\n",
    "        visual_feature = self.FeatureExtraction(input)\n",
    "        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))\n",
    "        visual_feature = visual_feature.squeeze(3)\n",
    "        \n",
    "        # Sequence modeling\n",
    "        contextual_feature = self.SequenceModeling(visual_feature)\n",
    "        \n",
    "        # Prediction\n",
    "        prediction = self.Prediction(contextual_feature.contiguous())\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "class VGG_FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel=512):\n",
    "        super(VGG_FeatureExtractor, self).__init__()\n",
    "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
    "                               int(output_channel / 2), output_channel]\n",
    "        \n",
    "        self.ConvNet = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, self.output_channel[0], 3, 1, 1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(self.output_channel[0], self.output_channel[1], 3, 1, 1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(self.output_channel[1], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(self.output_channel[2], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),\n",
    "            nn.Conv2d(self.output_channel[2], self.output_channel[3], 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.Conv2d(self.output_channel[3], self.output_channel[3], 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),\n",
    "            nn.Conv2d(self.output_channel[3], self.output_channel[3], 2, 1, 0), nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.ConvNet(input)\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.rnn.flatten_parameters()\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        output = self.linear(recurrent)\n",
    "        return output\n",
    "'''\n",
    "\n",
    "network_file = os.path.join(easyocr_user_network, \"taiwan_custom.py\")\n",
    "with open(network_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(network_code)\n",
    "\n",
    "print(f\"âœ… å·²å»ºç«‹: {network_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æª”æ¡ˆ 2: taiwan_custom.yaml (æ¨¡å‹é…ç½®)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è®€å–å­—ç¬¦é›†\n",
    "with open(charset_file, 'r', encoding='utf-8') as f:\n",
    "    charset = f.read().strip()\n",
    "\n",
    "yaml_content = f'''network_params:\n",
    "  input_channel: 1\n",
    "  output_channel: 512\n",
    "  hidden_size: 256\n",
    "\n",
    "character: '{charset}'\n",
    "\n",
    "model_name: 'taiwan_custom'\n",
    "'''\n",
    "\n",
    "yaml_file = os.path.join(easyocr_user_network, \"taiwan_custom.yaml\")\n",
    "with open(yaml_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"âœ… å·²å»ºç«‹: {yaml_file}\")\n",
    "print(f\"   å­—ç¬¦é›†åŒ…å« {len(charset)} å€‹å­—ç¬¦\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æª”æ¡ˆ 3: taiwan_custom.pth (æ¨¡å‹æ¬Šé‡)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "è¨“ç·´å®Œæˆå¾Œ,å°‡ best_accuracy.pth è¤‡è£½åˆ°:\n",
    "{easyocr_model_dir}/taiwan_custom.pth\n",
    "\n",
    "æŒ‡ä»¤:\n",
    "cp ~/easyocr_training/training_data/saved_models/best_accuracy.pth \\\\\n",
    "   {easyocr_model_dir}/taiwan_custom.pth\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æª”æ¡ˆä½ç½®ç¸½çµ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "1. taiwan_custom.py   â†’ {network_file}\n",
    "2. taiwan_custom.yaml â†’ {yaml_file}\n",
    "3. taiwan_custom.pth  â†’ {easyocr_model_dir}/taiwan_custom.pth (è¨“ç·´å¾Œè¤‡è£½)\n",
    "\n",
    "ä¸‰å€‹æª”æ¡ˆå¿…é ˆåŒå (taiwan_custom),ä½†å‰¯æª”åä¸åŒ!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871a9ec",
   "metadata": {},
   "source": [
    "---\n",
    "## éšæ®µ 6ï¸âƒ£: ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹\n",
    "\n",
    "è¨“ç·´å®Œæˆä¸¦æº–å‚™å¥½ 3 å€‹æª”æ¡ˆå¾Œ,å°±å¯ä»¥ä½¿ç”¨è‡ªè¨‚æ¨¡å‹äº†!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæ®µ 6: ä½¿ç”¨è‡ªè¨“ç·´çš„æ¨¡å‹é€²è¡Œ OCR\n",
    "\n",
    "import easyocr\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "easyocr_user_network = os.path.expanduser(\"~/.EasyOCR/user_network\")\n",
    "easyocr_model_dir = os.path.expanduser(\"~/.EasyOCR/model\")\n",
    "\n",
    "required_files = {\n",
    "    'taiwan_custom.py': os.path.join(easyocr_user_network, 'taiwan_custom.py'),\n",
    "    'taiwan_custom.yaml': os.path.join(easyocr_user_network, 'taiwan_custom.yaml'),\n",
    "    'taiwan_custom.pth': os.path.join(easyocr_model_dir, 'taiwan_custom.pth'),\n",
    "}\n",
    "\n",
    "print(\"æª¢æŸ¥å¿…è¦æª”æ¡ˆ:\")\n",
    "all_ready = True\n",
    "for name, path in required_files.items():\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"{status} {name:25s} - {path}\")\n",
    "    if not exists:\n",
    "        all_ready = False\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\nâœ… æ‰€æœ‰æª”æ¡ˆå°±ç·’,å¯ä»¥ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹!\")\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"è¼‰å…¥è‡ªè¨“ç·´æ¨¡å‹\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹\n",
    "        reader = easyocr.Reader(\n",
    "            ['ch_tra', 'en'],\n",
    "            recog_network='taiwan_custom',  # ä½¿ç”¨è‡ªè¨“ç·´æ¨¡å‹\n",
    "            gpu=True\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ!\")\n",
    "        \n",
    "        # æ¸¬è©¦è¾¨è­˜\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"æ¸¬è©¦è‡ªè¨“ç·´æ¨¡å‹\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        image_path = './samples/2.jpeg'\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            results = reader.readtext(image_path, detail=1)\n",
    "            \n",
    "            print(\"è¾¨è­˜çµæœ:\")\n",
    "            for bbox, text, conf in results:\n",
    "                if conf > 0.3:\n",
    "                    # æª¢æŸ¥æ˜¯å¦æ­£ç¢ºè¾¨è­˜ 'è‡º' å­—\n",
    "                    has_tai = 'è‡º' in text\n",
    "                    marker = \"âœ…\" if has_tai else \"\"\n",
    "                    print(f\"[{conf:.2f}] {text} {marker}\")\n",
    "            \n",
    "            # æª¢æŸ¥å®Œæ•´åœ°å€\n",
    "            full_text = ' '.join([text for _, text, conf in results if conf > 0.3])\n",
    "            if 'å¹³è‡º' in full_text or 'è‡º' in full_text:\n",
    "                print(\"\\nâœ… æˆåŠŸè¾¨è­˜ 'è‡º' å­—!\")\n",
    "            else:\n",
    "                print(\"\\nâš ï¸ æœªè¾¨è­˜åˆ° 'è‡º' å­—\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {image_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ éŒ¯èª¤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"\\nâš ï¸ è«‹å…ˆå®Œæˆè¨“ç·´ä¸¦æº–å‚™å¥½æ‰€æœ‰æª”æ¡ˆ\")\n",
    "    print(\"\\nç¼ºå°‘çš„æª”æ¡ˆ:\")\n",
    "    for name, path in required_files.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"  - {path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å°æ¯”æ¸¬è©¦\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "å¦‚æœè¦å°æ¯”åŸå§‹æ¨¡å‹å’Œè‡ªè¨“ç·´æ¨¡å‹:\n",
    "\n",
    "# åŸå§‹æ¨¡å‹\n",
    "reader_original = easyocr.Reader(['ch_tra', 'en'], gpu=True)\n",
    "results_original = reader_original.readtext('./samples/2.jpeg')\n",
    "\n",
    "# è‡ªè¨“ç·´æ¨¡å‹\n",
    "reader_custom = easyocr.Reader(['ch_tra', 'en'], recog_network='taiwan_custom', gpu=True)\n",
    "results_custom = reader_custom.readtext('./samples/2.jpeg')\n",
    "\n",
    "# æ¯”è¼ƒçµæœ\n",
    "print(\"åŸå§‹æ¨¡å‹:\", results_original)\n",
    "print(\"è‡ªè¨“ç·´æ¨¡å‹:\", results_custom)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763ea9b",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“‹ å®Œæ•´æµç¨‹æª¢æŸ¥æ¸…å–®\n",
    "\n",
    "### âœ… æº–å‚™éšæ®µ\n",
    "- [ ] å®‰è£ PyTorch å’Œ CUDA (å¦‚æœ‰ GPU)\n",
    "- [ ] å®‰è£ trdg (TextRecognitionDataGenerator)\n",
    "- [ ] å®‰è£ lmdb, Pillow, easyocr\n",
    "- [ ] Clone deep-text-recognition-benchmark\n",
    "\n",
    "### âœ… è³‡æ–™æº–å‚™éšæ®µ\n",
    "- [ ] å»ºç«‹å°ç£è©å½™è¡¨ (åŒ…å« 'è‡º' å­—)\n",
    "- [ ] ç”Ÿæˆå­—ç¬¦é›† (ç¢ºèªåŒ…å« 'è‡º')\n",
    "- [ ] ä½¿ç”¨ trdg ç”Ÿæˆ 2000+ å¼µè¨“ç·´åœ–ç‰‡\n",
    "- [ ] è½‰æ›ç‚º LMDB æ ¼å¼\n",
    "- [ ] åˆ†å‰²è¨“ç·´é›† (80%) å’Œé©—è­‰é›† (20%)\n",
    "\n",
    "### âœ… è¨“ç·´éšæ®µ\n",
    "- [ ] é…ç½®è¨“ç·´åƒæ•¸ (None-VGG-BiLSTM-CTC)\n",
    "- [ ] åŸ·è¡Œè¨“ç·´æŒ‡ä»¤\n",
    "- [ ] ç›£æ§è¨“ç·´é€²åº¦ (é©—è­‰æº–ç¢ºç‡)\n",
    "- [ ] ç­‰å¾…è¨“ç·´å®Œæˆ (10000 iterations)\n",
    "\n",
    "### âœ… éƒ¨ç½²éšæ®µ\n",
    "- [ ] å»ºç«‹ taiwan_custom.py (ç¶²è·¯å®šç¾©)\n",
    "- [ ] å»ºç«‹ taiwan_custom.yaml (æ¨¡å‹é…ç½®)\n",
    "- [ ] è¤‡è£½ best_accuracy.pth â†’ taiwan_custom.pth\n",
    "- [ ] æ¸¬è©¦è‡ªè¨“ç·´æ¨¡å‹\n",
    "- [ ] é©—è­‰ 'è‡º' å­—è¾¨è­˜æº–ç¢ºç‡\n",
    "\n",
    "---\n",
    "\n",
    "## â±ï¸ é ä¼°æ™‚é–“è»¸\n",
    "\n",
    "| éšæ®µ | æ™‚é–“ | èªªæ˜ |\n",
    "|------|------|------|\n",
    "| ç’°å¢ƒæº–å‚™ | 30åˆ†é˜ | å®‰è£å¥—ä»¶ã€clone repository |\n",
    "| è³‡æ–™æº–å‚™ | 1-2å°æ™‚ | ç”Ÿæˆåœ–ç‰‡ã€è½‰æ›æ ¼å¼ |\n",
    "| è¨“ç·´ | 4-12å°æ™‚ | å–æ±ºæ–¼ GPU (æˆ–ä½¿ç”¨ Colab) |\n",
    "| éƒ¨ç½²æ¸¬è©¦ | 30åˆ†é˜ | æº–å‚™æª”æ¡ˆã€æ¸¬è©¦æ¨¡å‹ |\n",
    "| **ç¸½è¨ˆ** | **6-15å°æ™‚** | ä¸å«ç­‰å¾…è¨“ç·´æ™‚é–“ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’° æˆæœ¬ä¼°ç®—\n",
    "\n",
    "### é¸é … A: ä½¿ç”¨è‡ªå·±çš„ GPU\n",
    "- é›»è²»: ç´„ $2-5 (è¨“ç·´ 8-12 å°æ™‚)\n",
    "- ç¸½æˆæœ¬: **$2-5**\n",
    "\n",
    "### é¸é … B: ä½¿ç”¨é›²ç«¯ GPU\n",
    "- Google Colab Pro: $10/æœˆ (V100 GPU, 24å°æ™‚é€£çºŒ)\n",
    "- AWS p3.2xlarge: $3.06/å°æ™‚ Ã— 8å°æ™‚ = **$24.48**\n",
    "- Azure NC6: $0.90/å°æ™‚ Ã— 8å°æ™‚ = **$7.20**\n",
    "\n",
    "### é¸é … C: ç›´æ¥ä½¿ç”¨å¾Œè™•ç† (æ¨è–¦!)\n",
    "- æˆæœ¬: **$0**\n",
    "- æ™‚é–“: **5åˆ†é˜**\n",
    "- æ•ˆæœ: **95%+ æº–ç¢ºç‡**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ€çµ‚å»ºè­°\n",
    "\n",
    "1. **ç«‹å³å¯ç”¨**: å…ˆåŸ·è¡Œæœ¬ notebook é–‹é ­çš„ã€Œæ–¹æ¡ˆ 1: å¾Œè™•ç†ä¿®æ­£ã€\n",
    "   - é›¶æˆæœ¬ã€ç«‹å³è¦‹æ•ˆ\n",
    "   - å¯è§£æ±ºå¤§éƒ¨åˆ† 'è‡º' å­—å•é¡Œ\n",
    "\n",
    "2. **çŸ­æœŸæ–¹æ¡ˆ**: å¦‚æœå¾Œè™•ç†ä¸å¤ å®Œç¾\n",
    "   - å¢åŠ æ›´å¤šéŒ¯èª¤å°ç…§è¦å‰‡\n",
    "   - ä½¿ç”¨å¤šæ¨¡å‹æ•´åˆ (Ensemble)\n",
    "\n",
    "3. **é•·æœŸæ–¹æ¡ˆ**: åªåœ¨ä»¥ä¸‹æƒ…æ³æ‰è¨“ç·´æ¨¡å‹\n",
    "   - å¾Œè™•ç†ç„¡æ³•è¦†è“‹æ‰€æœ‰æƒ…æ³\n",
    "   - éœ€è¦è™•ç†å¤§é‡ä¸åŒçš„åœ°å€æ ¼å¼\n",
    "   - æœ‰å……è¶³çš„æ™‚é–“å’Œé ç®—\n",
    "   - æœ‰ GPU è³‡æºæˆ–é¡˜æ„ä½¿ç”¨é›²ç«¯æœå‹™\n",
    "\n",
    "ğŸ’¡ **å¯¦å‹™ä¸Š,90% çš„æƒ…æ³ä½¿ç”¨å¾Œè™•ç†å°±è¶³å¤ äº†!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
